{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "from dataclasses import dataclass\n",
    "\n",
    "PROJECT_PATH = \"/data1/datasets_1/human_cistrome/chip-atlas/peak_calls/tfbinding_scripts/tf-binding\"\n",
    "\n",
    "@dataclass\n",
    "class SampleConfig:\n",
    "    label: str\n",
    "    sample: str\n",
    "    ground_truth_file: str\n",
    "\n",
    "# create a list of SampleConfig objects\n",
    "sample_configs = [\n",
    "    SampleConfig(label=\"AR\", sample=\"22Rv1\", ground_truth_file=f\"{PROJECT_PATH}/data/transcription_factors/AR/merged/22RV1_AR_merged.bed\"),\n",
    "    SampleConfig(label=\"FOXA1\", sample=\"22Rv1\", ground_truth_file=f\"{PROJECT_PATH}/data/transcription_factors/FOXA1/merged/22RV1_FOXA1_merged.bed\"),\n",
    "    SampleConfig(label=\"ASCL1\", sample=\"42D-ENZR\", ground_truth_file=f\"{PROJECT_PATH}/data/transcription_factors/ASCL1/merged/42D-ENZR_ASCL1_merged.bed\"),\n",
    "\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from src.utils.generate_training_peaks import run_bedtools_command\n",
    "def intersect_bed_files(main_df: pl.DataFrame, intersect_df: pl.DataFrame, region_type: str = None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Intersect two BED files using bedtools and return the original DataFrame with overlap flags.\n",
    "    \n",
    "    Args:\n",
    "        main_df: Primary Polars DataFrame with BED data\n",
    "        intersect_df: Secondary Polars DataFrame to intersect with\n",
    "        region_type: Optional region type label to add to results\n",
    "        \n",
    "    Returns:\n",
    "        Original DataFrame with additional column indicating overlaps\n",
    "    \"\"\"\n",
    "    with tempfile.NamedTemporaryFile(delete=False, mode='w') as main_file, \\\n",
    "         tempfile.NamedTemporaryFile(delete=False, mode='w') as intersect_file, \\\n",
    "         tempfile.NamedTemporaryFile(delete=False, mode='w') as result_file:\n",
    "        \n",
    "        main_path = main_file.name\n",
    "        intersect_path = intersect_file.name\n",
    "        result_path = result_file.name\n",
    "\n",
    "        # Write DataFrames to temporary files\n",
    "        main_df.write_csv(main_path, separator=\"\\t\", include_header=False)\n",
    "        intersect_df.write_csv(intersect_path, separator=\"\\t\", include_header=False)\n",
    "\n",
    "        # Run bedtools intersect with -c flag to count overlaps\n",
    "        command = f\"bedtools intersect -a {main_path} -b {intersect_path} -c > {result_path}\"\n",
    "        run_bedtools_command(command)\n",
    "\n",
    "        # Read results back into Polars DataFrame\n",
    "        result_df = pl.read_csv(\n",
    "            result_path,\n",
    "            separator=\"\\t\",\n",
    "            has_header=False,\n",
    "            new_columns=[*main_df.columns, \"overlap_count\"]\n",
    "        )\n",
    "\n",
    "    # Clean up temporary files\n",
    "    os.remove(main_path)\n",
    "    os.remove(intersect_path) \n",
    "    os.remove(result_path)\n",
    "\n",
    "    # Add boolean overlap column\n",
    "    result_df = result_df.with_columns(\n",
    "        pl.col(\"overlap_count\").gt(0).alias(\"overlaps_ground_truth\")\n",
    "    ).drop(\"overlap_count\")\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory (os error 2): ..._calls/tfbinding_scripts/tf-binding/data/processed_results/ASCL1_22Rv1_processed.parquet\n\nThis error occurred with the following context stack:\n\t[1] 'parquet scan'\n\t[2] 'select'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m parquet_path \u001b[38;5;241m=\u001b[39m PROJECT_PATH \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data/processed_results/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m sample_config\u001b[38;5;241m.\u001b[39mlabel \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m sample_config\u001b[38;5;241m.\u001b[39msample \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_processed.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# print(parquet_path)\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparquet_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchr_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstart\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcell_line\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtargets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredicted\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweights\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprobabilities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mrename({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchr_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchr\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m     26\u001b[0m chip_data \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mread_csv(sample_config\u001b[38;5;241m.\u001b[39mground_truth_file, separator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, has_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, new_columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/processing/lib/python3.10/site-packages/polars/_utils/deprecation.py:92\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m     89\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m     90\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, version\n\u001b[1;32m     91\u001b[0m     )\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/processing/lib/python3.10/site-packages/polars/_utils/deprecation.py:92\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m     89\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m     90\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, version\n\u001b[1;32m     91\u001b[0m     )\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/processing/lib/python3.10/site-packages/polars/io/parquet/functions.py:231\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(source, columns, n_rows, row_index_name, row_index_offset, parallel, use_statistics, hive_partitioning, glob, schema, hive_schema, try_parse_hive_dates, rechunk, low_memory, storage_options, retries, use_pyarrow, pyarrow_options, memory_map, include_file_paths, allow_missing_columns)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m         lf \u001b[38;5;241m=\u001b[39m lf\u001b[38;5;241m.\u001b[39mselect(columns)\n\u001b[0;32m--> 231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/processing/lib/python3.10/site-packages/polars/lazyframe/frame.py:2055\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, streaming, engine, background, _eager, **_kwargs)\u001b[0m\n\u001b[1;32m   2053\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[1;32m   2054\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[0;32m-> 2055\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory (os error 2): ..._calls/tfbinding_scripts/tf-binding/data/processed_results/ASCL1_22Rv1_processed.parquet\n\nThis error occurred with the following context stack:\n\t[1] 'parquet scan'\n\t[2] 'select'\n"
     ]
    }
   ],
   "source": [
    "# Add dfs to list\n",
    "HIGH_COUNT_QUANTILE = 0.75\n",
    "MAX_COUNT_THRESHOLD = 30\n",
    "MID_COUNT_THRESHOLD = 10\n",
    "\n",
    "\n",
    "def threshold_peaks(df):\n",
    "    max_count = df.select(pl.col(\"count\").max()).item()\n",
    "    \n",
    "    if max_count <= 2:\n",
    "        return df\n",
    "    elif max_count > MAX_COUNT_THRESHOLD:\n",
    "        threshold = df.select(pl.col(\"count\").quantile(HIGH_COUNT_QUANTILE)).item()\n",
    "        df = df.filter(pl.col(\"count\") > threshold)\n",
    "    elif max_count > MID_COUNT_THRESHOLD:\n",
    "        threshold = df.select(pl.col(\"count\").median()).item()\n",
    "        df = df.filter(pl.col(\"count\") > threshold)\n",
    "    return df\n",
    "\n",
    "dfs = []\n",
    "for sample_config in sample_configs:\n",
    "    parquet_path = PROJECT_PATH + \"/data/processed_results/\" + sample_config.label + \"_\" + sample_config.sample + \"_processed.parquet\"\n",
    "    # print(parquet_path)\n",
    "    df = pl.read_parquet(parquet_path, columns=[\"chr_name\", \"start\", \"end\", \"cell_line\", \"targets\", \"predicted\", \"weights\", \"probabilities\"])\n",
    "    df = df.rename({\"chr_name\": \"chr\"})\n",
    "    chip_data = pl.read_csv(sample_config.ground_truth_file, separator=\"\\t\", has_header=False, new_columns=[\"chr\", \"start\", \"end\", \"count\"])\n",
    "    chip_data = threshold_peaks(chip_data)\n",
    "    intersected_df = intersect_bed_files(df[[\"chr\", \"start\", \"end\"]], chip_data)\n",
    "    ground_truth_df = df.join(intersected_df, on=[\"chr\", \"start\", \"end\"], how=\"left\")\n",
    "    ground_truth_df = ground_truth_df.with_columns(pl.when(pl.col(\"overlaps_ground_truth\")).then(1).otherwise(0).alias(\"targets\"))\n",
    "    ground_truth_df = ground_truth_df.drop(\"overlaps_ground_truth\")\n",
    "    dfs.append(ground_truth_df)\n",
    "\n",
    "dfs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_recall_curve, roc_curve, auc, f1_score, confusion_matrix\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mensure_numpy\u001b[39m(arr):\n",
      "File \u001b[0;32m~/miniconda3/envs/processing/lib/python3.10/site-packages/sklearn/__init__.py:82\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# in utils.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# (OpenMP is loaded by importing show_versions right after this block)\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthreadpoolctl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ThreadpoolController\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/processing/lib/python3.10/site-packages/scipy/linalg/__init__.py:222\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_procrustes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp_update\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sketches\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp_cossin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/processing/lib/python3.10/site-packages/scipy/linalg/_sketches.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_random_state, rng_integers\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csc_matrix\n\u001b[1;32m     11\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclarkson_woodruff_transform\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcwt_matrix\u001b[39m(n_rows, n_columns, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/processing/lib/python3.10/site-packages/scipy/sparse/__init__.py:308\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matrix_io\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# For backward compatibility with v0.19.\u001b[39;00m\n\u001b[0;32m--> 308\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csgraph\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    312\u001b[0m     base, bsr, compressed, construct, coo, csc, csr, data, dia, dok, extract,\n\u001b[1;32m    313\u001b[0m     lil, sparsetools, sputils\n\u001b[1;32m    314\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/processing/lib/python3.10/site-packages/scipy/sparse/csgraph/__init__.py:185\u001b[0m\n\u001b[1;32m    157\u001b[0m __docformat__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrestructuredtext en\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconnected_components\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    160\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlaplacian\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    161\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshortest_path\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsgraph_to_masked\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    183\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNegativeCycleError\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_laplacian\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m laplacian\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shortest_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    187\u001b[0m     shortest_path, floyd_warshall, dijkstra, bellman_ford, johnson,\n\u001b[1;32m    188\u001b[0m     NegativeCycleError\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_traversal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    191\u001b[0m     breadth_first_order, depth_first_order, breadth_first_tree,\n\u001b[1;32m    192\u001b[0m     depth_first_tree, connected_components\n\u001b[1;32m    193\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/processing/lib/python3.10/site-packages/scipy/sparse/csgraph/_laplacian.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearOperator\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_pydata_sparse_to_scipy, is_pydata_spmatrix\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Graph laplacian\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/processing/lib/python3.10/site-packages/scipy/sparse/linalg/__init__.py:132\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dsolve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_interface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m--> 132\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_eigen\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matfuncs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_onenormest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/processing/lib/python3.10/site-packages/scipy/sparse/linalg/_eigen/__init__.py:10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mSparse Eigenvalue Solvers\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m-------------------------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marpack\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlobpcg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_svds\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m svds\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m arpack\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:975\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1074\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ensure_numpy(arr):\n",
    "    \"\"\"Convert input to numpy array if it isn't already.\"\"\"\n",
    "    return np.array(arr) if not isinstance(arr, np.ndarray) else arr\n",
    "\n",
    "def find_best_f1_threshold(y_true, y_score):\n",
    "    \"\"\"Find the optimal threshold that gives the best F1 score.\"\"\"\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_score)\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-7)\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 1.0\n",
    "    return best_threshold, f1_scores[best_idx]\n",
    "\n",
    "def get_display_name(config):\n",
    "    \"\"\"Get display name based on sample and label if available.\"\"\"\n",
    "    return f\"{config.label} ({config.sample})\" if hasattr(config, 'label') and config.label else config.sample\n",
    "\n",
    "def print_confusion_metrics(dfs, sample_configs, threshold=None):\n",
    "    \"\"\"\n",
    "    Print confusion matrix metrics for multiple datasets.\n",
    "    \n",
    "    Args:\n",
    "        dfs: List of dataframes containing targets and probabilities\n",
    "        sample_configs: List of sample configurations for labeling\n",
    "        threshold: Optional fixed threshold to use. If None, finds best F1 threshold\n",
    "    \"\"\"\n",
    "    print(\"\\nConfusion Matrix Metrics:\")\n",
    "    print(\"-\" * 140)\n",
    "    headers = [\"Dataset\", \"Threshold\", \"True Negative\", \"False Positive\", \"False Negative\", \"True Positive\", \"Total\", \"Accuracy\"]\n",
    "    print(f\"{headers[0]:<25} {headers[1]:<10} {headers[2]:<15} {headers[3]:<15} {headers[4]:<15} {headers[5]:<15} {headers[6]:<10} {headers[7]:<10}\")\n",
    "    print(\"-\" * 140)\n",
    "    \n",
    "    for df, config in zip(dfs, sample_configs):\n",
    "        y_true = ensure_numpy(df[\"targets\"])\n",
    "        y_score = ensure_numpy(df[\"probabilities\"])\n",
    "        \n",
    "        # Determine threshold\n",
    "        if threshold is None:\n",
    "            best_threshold, _ = find_best_f1_threshold(y_true, y_score)\n",
    "            used_threshold = best_threshold\n",
    "        else:\n",
    "            used_threshold = threshold\n",
    "        \n",
    "        # Get predictions using threshold\n",
    "        y_pred = (y_score >= used_threshold).astype(int)\n",
    "        \n",
    "        # Calculate confusion matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        accuracy = (tp + tn) / total\n",
    "        \n",
    "        display_name = get_display_name(config)\n",
    "        print(f\"{display_name:<25} {used_threshold:>9.3f} {tn:>15} {fp:>15} {fn:>15} {tp:>15} {total:>10} {accuracy:>9.3f}\")\n",
    "    \n",
    "    print(\"-\" * 140)\n",
    "\n",
    "def plot_performance_curves(dfs, sample_configs, threshold=None):\n",
    "    \"\"\"\n",
    "    Plot ROC and PR curves for multiple datasets side by side.\n",
    "    \n",
    "    Args:\n",
    "        dfs: List of dataframes containing targets and probabilities\n",
    "        sample_configs: List of sample configurations for labeling\n",
    "        threshold: Optional fixed threshold to use. If None, finds best F1 threshold\n",
    "    \"\"\"\n",
    "    fig, (ax_roc, ax_pr) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(dfs)))\n",
    "    \n",
    "    print(\"\\nPerformance Metrics:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Dataset':<25} {'Threshold':<10} {'F1 Score':<10} {'ROC AUC':<10} {'PR AUC':<10}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for idx, (df, config, color) in enumerate(zip(dfs, sample_configs, colors)):\n",
    "        y_true = ensure_numpy(df[\"targets\"])\n",
    "        y_score = ensure_numpy(df[\"probabilities\"])\n",
    "        display_name = get_display_name(config)\n",
    "        \n",
    "        # Determine threshold\n",
    "        if threshold is None:\n",
    "            best_threshold, _ = find_best_f1_threshold(y_true, y_score)\n",
    "            used_threshold = best_threshold\n",
    "        else:\n",
    "            used_threshold = threshold\n",
    "        \n",
    "        # Get predictions for F1 score\n",
    "        y_pred = (y_score >= used_threshold).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        \n",
    "        # ROC curve\n",
    "        fpr, tpr, roc_thresholds = roc_curve(y_true, y_score)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        # Plot ROC curve\n",
    "        ax_roc.plot(fpr, tpr, color=color, lw=2,\n",
    "                   label=f'{display_name} (AUC = {roc_auc:.3f})')\n",
    "                   \n",
    "        # Find and plot threshold point on ROC\n",
    "        thresh_idx = np.argmin(np.abs(roc_thresholds - used_threshold))\n",
    "        ax_roc.plot(fpr[thresh_idx], tpr[thresh_idx], 'o', color=color,\n",
    "                   label=f'Threshold = {used_threshold:.3f}')\n",
    "        \n",
    "        # PR curve\n",
    "        precision, recall, pr_thresholds = precision_recall_curve(y_true, y_score)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        \n",
    "        # Plot PR curve\n",
    "        ax_pr.plot(recall, precision, color=color, lw=2,\n",
    "                  label=f'{display_name} (AUC = {pr_auc:.3f})')\n",
    "                  \n",
    "        # Find and plot threshold point on PR\n",
    "        if len(pr_thresholds) > 0:  # Handle edge case\n",
    "            thresh_idx = np.argmin(np.abs(pr_thresholds - used_threshold))\n",
    "            if thresh_idx < len(recall):  # Ensure index is valid\n",
    "                ax_pr.plot(recall[thresh_idx], precision[thresh_idx], 'o', \n",
    "                         color=color,\n",
    "                         label=f'Threshold = {used_threshold:.3f}')\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"{display_name:<25} {used_threshold:.3f}     {f1:.3f}     \"\n",
    "              f\"{roc_auc:.3f}     {pr_auc:.3f}\")\n",
    "    \n",
    "    # ROC plot settings\n",
    "    ax_roc.plot([0, 1], [0, 1], 'k--', lw=1.5, label='Random')\n",
    "    ax_roc.set_xlim([-0.05, 1.05])\n",
    "    ax_roc.set_ylim([-0.05, 1.05])\n",
    "    ax_roc.set_xlabel('False Positive Rate')\n",
    "    ax_roc.set_ylabel('True Positive Rate')\n",
    "    ax_roc.set_title('Receiver Operating Characteristic (ROC) Curves')\n",
    "    ax_roc.legend(loc='lower right', fontsize='small')\n",
    "    ax_roc.grid(True, alpha=0.3)\n",
    "    \n",
    "    # PR plot settings\n",
    "    ax_pr.set_xlim([-0.05, 1.05])\n",
    "    ax_pr.set_ylim([-0.05, 1.05])\n",
    "    ax_pr.set_xlabel('Recall')\n",
    "    ax_pr.set_ylabel('Precision')\n",
    "    ax_pr.set_title('Precision-Recall Curves')\n",
    "    ax_pr.legend(loc='lower left', fontsize='small')\n",
    "    ax_pr.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Use with fixed threshold can also do None for best F1 threshold\n",
    "threshold = None\n",
    "plot_performance_curves(dfs, sample_configs, threshold=threshold)\n",
    "print_confusion_metrics(dfs, sample_configs, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
