{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "\n",
        "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
        "sys.path.append(notebook_dir)\n",
        "\n",
        "\n",
        "\n",
        "project_path = \"/data1/datasets_1/human_cistrome/chip-atlas/peak_calls/tfbinding_scripts/tf-binding\"\n",
        "model = \"AR\"\n",
        "sample = \"22Rv1\"\n",
        "jaspar_file = f\"/data1/datasets_1/human_cistrome/chip-atlas/peak_calls/tfbinding_scripts/tf-binding/src/analysis/interpretability/motifs/AR.jaspar\"  # Update this path\n",
        "ground_truth_file = f\"/data1/datasets_1/human_cistrome/chip-atlas/peak_calls/tfbinding_scripts/tf-binding/data/transcription_factors/AR/merged/22RV1_AR_merged.bed\"\n",
        "\n",
        "df = pl.read_parquet(\"/data1/datasets_1/human_cistrome/chip-atlas/peak_calls/tfbinding_scripts/tf-binding/data/processed_results/AR_22Rv1_processed.parquet\", \n",
        "                    columns=[\"chr_name\", \"start\", \"end\", \"cell_line\", \"targets\", \"predicted\", \"weights\", \"probabilities\", \"attributions\"],\n",
        "                    parallel=\"columns\",                     # Enable parallel reading\n",
        "                    use_statistics=True,                    # Use parquet statistics\n",
        "                    memory_map=True).lazy()                         # Use memory mapping\n",
        "df = df.rename({\"chr_name\": \"chr\"})\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import tempfile\n",
        "import polars as pl\n",
        "from src.utils.generate_training_peaks import run_bedtools_command\n",
        "\n",
        "def intersect_bed_files(main_df: pl.LazyFrame, intersect_df: pl.DataFrame, region_type: str = None) -> pl.LazyFrame:\n",
        "    \"\"\"\n",
        "    Intersect two BED files using bedtools and return the original DataFrame with overlap flags.\n",
        "    Args:\n",
        "    main_df: Primary Polars DataFrame with BED data\n",
        "    intersect_df: Secondary Polars DataFrame to intersect with\n",
        "    region_type: Optional region type label to add to results\n",
        "    Returns:\n",
        "    Original DataFrame with additional column indicating overlaps\n",
        "    \"\"\"\n",
        "    # Get column names from schema\n",
        "    main_cols = main_df.schema.keys()\n",
        "    \n",
        "    with tempfile.NamedTemporaryFile(delete=False, mode='w') as main_file, \\\n",
        "         tempfile.NamedTemporaryFile(delete=False, mode='w') as intersect_file, \\\n",
        "         tempfile.NamedTemporaryFile(delete=False, mode='w') as result_file:\n",
        "        main_path = main_file.name\n",
        "        intersect_path = intersect_file.name\n",
        "        result_path = result_file.name\n",
        "        \n",
        "        # Write DataFrames to temporary files - collect LazyFrame first\n",
        "        main_df.collect().write_csv(main_path, separator=\"\\t\", include_header=False)\n",
        "        intersect_df.write_csv(intersect_path, separator=\"\\t\", include_header=False)\n",
        "        \n",
        "        # Run bedtools intersect with -c flag to count overlaps\n",
        "        command = f\"bedtools intersect -a {main_path} -b {intersect_path} -c > {result_path}\"\n",
        "        run_bedtools_command(command)\n",
        "        \n",
        "        # Read results back into Polars DataFrame\n",
        "        result_df = pl.read_csv(\n",
        "            result_path,\n",
        "            separator=\"\\t\",\n",
        "            has_header=False,\n",
        "            new_columns=[*main_cols, \"overlap_count\"]\n",
        "        ).lazy()\n",
        "        \n",
        "        # Clean up temporary files\n",
        "        os.remove(main_path)\n",
        "        os.remove(intersect_path)\n",
        "        os.remove(result_path)\n",
        "        \n",
        "        # Add boolean overlap column\n",
        "        return result_df.with_columns(\n",
        "            pl.col(\"overlap_count\").gt(0).alias(\"overlaps_ground_truth\")\n",
        "        ).drop(\"overlap_count\")\n",
        "\n",
        "HIGH_COUNT_QUANTILE = 0.75\n",
        "MAX_COUNT_THRESHOLD = 30\n",
        "MID_COUNT_THRESHOLD = 10\n",
        "\n",
        "def threshold_peaks(df):\n",
        "    \"\"\"\n",
        "    Filter peaks based on count thresholds.\n",
        "    Works with both DataFrame and LazyFrame.\n",
        "    \"\"\"\n",
        "    # Handle scalar operations safely\n",
        "    def get_scalar(expr):\n",
        "        if isinstance(df, pl.LazyFrame):\n",
        "            return expr.collect().item()\n",
        "        return expr.item()\n",
        "    \n",
        "    max_count = get_scalar(df.select(pl.col(\"count\").max()))\n",
        "    \n",
        "    if max_count <= 2:\n",
        "        return df\n",
        "    elif max_count > MAX_COUNT_THRESHOLD:\n",
        "        threshold = get_scalar(df.select(pl.col(\"count\").quantile(HIGH_COUNT_QUANTILE)))\n",
        "        return df.filter(pl.col(\"count\") > threshold)\n",
        "    elif max_count > MID_COUNT_THRESHOLD:\n",
        "        threshold = get_scalar(df.select(pl.col(\"count\").median()))\n",
        "        return df.filter(pl.col(\"count\") > threshold)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Usage example:\n",
        "df_ground_truth = pl.read_csv(ground_truth_file,\n",
        "                             separator=\"\\t\",\n",
        "                             has_header=False,\n",
        "                             new_columns=[\"chr\", \"start\", \"end\", \"count\"],\n",
        "                             columns=[0,1,2,3])\n",
        "\n",
        "df_ground_truth_filtered = threshold_peaks(df_ground_truth)\n",
        "\n",
        "# Use select() instead of subscripting\n",
        "intersected_df = intersect_bed_files(df.select([\"chr\", \"start\", \"end\"]), df_ground_truth_filtered)\n",
        "\n",
        "# add overlaps ground truth to df from intersected_df\n",
        "ground_truth_df = df.join(intersected_df, on=[\"chr\", \"start\", \"end\"], how=\"left\")\n",
        "\n",
        "# add overlaps_ground_truth to df under targets, 1 if overlaps_ground_truth is true, 0 otherwise\n",
        "ground_truth_df = ground_truth_df.with_columns(\n",
        "    pl.when(pl.col(\"overlaps_ground_truth\")).then(1).otherwise(0).alias(\"targets\")\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Step 1: Keep the filtering lazy until collection\n",
        "# Corrected: Added parentheses around individual conditions\n",
        "df_positive_correct = ground_truth_df.filter(\n",
        "    (pl.col(\"targets\") == 1) & (pl.col(\"predicted\") == 1)\n",
        ").collect()\n",
        "\n",
        "# df_negative_correct_all = ground_truth_df.filter(\n",
        "#     (pl.col(\"targets\") == 0) & (pl.col(\"predicted\") == 0)\n",
        "# ).collect()\n",
        "\n",
        "# # Step 2: Get the count of positive samples\n",
        "# pos_count = len(df_positive_correct)\n",
        "\n",
        "# # Step 3: Sample from the materialized negative DataFrame\n",
        "# df_negative = df_negative_correct_all.sample(\n",
        "#     n=min(pos_count, len(df_negative_correct_all)), seed=42\n",
        "# )\n",
        "\n",
        "# # Step 4: Concatenate the two DataFrames\n",
        "# df_balanced = pl.concat([df_positive_correct, df_negative])\n",
        "\n",
        "# df_balanced\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from typing import Tuple, List, Dict\n",
        "import pysam\n",
        "\n",
        "def process_pileups(pileup_dir: Path, chr_name: str, start: int, end: int) -> pl.DataFrame:\n",
        "    \"\"\"Process pileup files for a given genomic region with 4096bp context.\"\"\"\n",
        "    context_length = 4_096\n",
        "    interval_length = end - start\n",
        "    extra_seq = context_length - interval_length\n",
        "    extra_left_seq = extra_seq // 2\n",
        "    extra_right_seq = extra_seq - extra_left_seq\n",
        "    start -= extra_left_seq\n",
        "    end += extra_right_seq\n",
        "    \n",
        "    # Get the pileup file for the given chromosome\n",
        "    pileup_file = pileup_dir / f\"{chr_name}.pileup.gz\"\n",
        "    assert pileup_file.exists(), f\"pileup file for {pileup_file} does not exist\"\n",
        "    \n",
        "    tabixfile = pysam.TabixFile(str(pileup_file))\n",
        "    records = []\n",
        "    for rec in tabixfile.fetch(chr_name, start, end):\n",
        "        records.append(rec.split(\"\\t\"))\n",
        "    \n",
        "    # Convert records to a DataFrame using Polars\n",
        "    df = pl.DataFrame({\n",
        "        \"chr_name\": [rec[0] for rec in records],\n",
        "        \"position\": [int(rec[1]) for rec in records],\n",
        "        \"nucleotide\": [rec[2] for rec in records],\n",
        "        \"count\": [float(rec[3]) for rec in records],\n",
        "    })\n",
        "    \n",
        "    return df\n",
        "\n",
        "\n",
        "def create_position_to_count_mapping(pileup_df: pl.DataFrame) -> Dict[int, float]:\n",
        "    \"\"\"Create a mapping from genomic position to ATAC count.\"\"\"\n",
        "    return dict(zip(pileup_df['position'].to_list(), pileup_df['count'].to_list()))\n",
        "\n",
        "\n",
        "def create_atac_pileup_array(position_count_map: Dict[int, float], \n",
        "                            start_pos: int, \n",
        "                            length: int = 4096) -> np.ndarray:\n",
        "    \"\"\"Create ATAC pileup array for a genomic region.\"\"\"\n",
        "    atac_array = np.zeros(length)\n",
        "    \n",
        "    for i in range(length):\n",
        "        pos = start_pos + i\n",
        "        if pos in position_count_map:\n",
        "            atac_array[i] = position_count_map[pos]\n",
        "    \n",
        "    return atac_array\n",
        "\n",
        "\n",
        "def reshape_attributions_fast(df: pl.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Fast reshape attribution data using vectorized operations.\n",
        "    \n",
        "    Returns:\n",
        "        attrs_list: Attribution scores for ACGT (shape: n_samples, 4, 4096)\n",
        "        atac_attribution_list: ATAC attribution scores (shape: n_samples, 4096)\n",
        "    \"\"\"\n",
        "    print(\"Reshaping attribution data...\")\n",
        "    # Convert to numpy array more efficiently\n",
        "    attributions = np.array(df['attributions'].to_list())\n",
        "    \n",
        "    # Vectorized reshape - much faster than loops\n",
        "    reshaped = attributions.reshape(-1, 4096, 5)\n",
        "    \n",
        "    # Split into ACGT and ATAC components\n",
        "    attrs_list = reshaped[..., :4].transpose(0, 2, 1)  # Shape: (n_samples, 4, 4096)\n",
        "    atac_attribution_list = reshaped[..., 4]  # Shape: (n_samples, 4096)\n",
        "            \n",
        "    return attrs_list, atac_attribution_list\n",
        "\n",
        "\n",
        "def process_pileups_batch(pileup_dir: Path, regions_df: pl.DataFrame) -> Dict[int, np.ndarray]:\n",
        "    \"\"\"Process multiple pileup regions for a single cell line efficiently.\"\"\"\n",
        "    context_length = 4_096\n",
        "    atac_arrays = {}\n",
        "    \n",
        "    # Get unique chromosomes to minimize file operations\n",
        "    chromosomes = regions_df['chr'].unique().to_list()\n",
        "    chr_tabix_files = {}\n",
        "    \n",
        "    # Open all needed tabix files once\n",
        "    print(f\"Opening tabix files for {len(chromosomes)} chromosomes...\")\n",
        "    for chr_name in tqdm(chromosomes, desc=\"Loading chromosome files\", leave=False):\n",
        "        pileup_file = pileup_dir / f\"{chr_name}.pileup.gz\"\n",
        "        if pileup_file.exists():\n",
        "            chr_tabix_files[chr_name] = pysam.TabixFile(str(pileup_file))\n",
        "    \n",
        "    # Process each region\n",
        "    region_iterator = regions_df.iter_rows(named=True)\n",
        "    total_regions = len(regions_df)\n",
        "    \n",
        "    for row in tqdm(region_iterator, total=total_regions, desc=\"Processing regions\", leave=False):\n",
        "        idx, chr_name, start, end = row['idx'], row['chr'], row['start'], row['end']\n",
        "        \n",
        "        # Calculate adjusted coordinates\n",
        "        interval_length = end - start\n",
        "        extra_seq = context_length - interval_length\n",
        "        extra_left_seq = extra_seq // 2\n",
        "        extra_right_seq = extra_seq - extra_left_seq\n",
        "        adj_start = start - extra_left_seq\n",
        "        adj_end = end + extra_right_seq\n",
        "        \n",
        "        # Initialize array\n",
        "        atac_array = np.zeros(context_length)\n",
        "        \n",
        "        # Get data if tabix file exists\n",
        "        if chr_name in chr_tabix_files:\n",
        "            tabixfile = chr_tabix_files[chr_name]\n",
        "            \n",
        "            # Collect all positions and counts at once\n",
        "            positions = []\n",
        "            counts = []\n",
        "            \n",
        "            try:\n",
        "                for rec in tabixfile.fetch(chr_name, adj_start, adj_end):\n",
        "                    fields = rec.split(\"\\t\")\n",
        "                    positions.append(int(fields[1]))\n",
        "                    counts.append(float(fields[3]))\n",
        "                \n",
        "                # Vectorized assignment\n",
        "                if positions:\n",
        "                    positions = np.array(positions)\n",
        "                    counts = np.array(counts)\n",
        "                    \n",
        "                    # Calculate array indices\n",
        "                    array_indices = positions - adj_start\n",
        "                    \n",
        "                    # Filter valid indices\n",
        "                    valid_mask = (array_indices >= 0) & (array_indices < context_length)\n",
        "                    valid_indices = array_indices[valid_mask]\n",
        "                    valid_counts = counts[valid_mask]\n",
        "                    \n",
        "                    # Assign values\n",
        "                    atac_array[valid_indices] = valid_counts\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not fetch data for {chr_name}:{adj_start}-{adj_end}: {e}\")\n",
        "        \n",
        "        atac_arrays[idx] = atac_array\n",
        "    \n",
        "    # Close tabix files\n",
        "    print(\"Closing tabix files...\")\n",
        "    for tabixfile in chr_tabix_files.values():\n",
        "        tabixfile.close()\n",
        "    \n",
        "    return atac_arrays\n",
        "\n",
        "\n",
        "def process_region_data_fast(df: pl.DataFrame, base_pileup_dir: Path = None) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Fast process both attribution and pileup data using Polars optimizations.\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame containing attribution data and region info (chr, start, end, cell_line columns)\n",
        "        base_pileup_dir: Base directory path for pileup files (optional, uses default if None)\n",
        "    \n",
        "    Returns:\n",
        "        attrs_list: Attribution scores for ACGT\n",
        "        atac_attribution_list: ATAC attribution scores\n",
        "        atac_pileup_list: Raw ATAC pileup counts\n",
        "    \"\"\"\n",
        "    if base_pileup_dir is None:\n",
        "        base_pileup_dir = Path(\"/data1/projects/human_cistrome/aligned_chip_data/merged_cell_lines/\")\n",
        "    \n",
        "    print(f\"Processing {len(df)} regions across cell lines...\")\n",
        "    \n",
        "    # Get attribution data (fast vectorized version)\n",
        "    attrs_list, atac_attribution_list = reshape_attributions_fast(df)\n",
        "    \n",
        "    # Add row index for tracking\n",
        "    df_with_idx = df.with_row_index(\"idx\")\n",
        "    \n",
        "    # Group by cell line for batch processing\n",
        "    atac_pileup_arrays = [None] * len(df)\n",
        "    cell_line_groups = list(df_with_idx.group_by(\"cell_line\"))\n",
        "    \n",
        "    print(f\"Processing {len(cell_line_groups)} cell lines...\")\n",
        "    \n",
        "    for cell_line, group_df in tqdm(cell_line_groups, desc=\"Processing cell lines\"):\n",
        "        cell_line_name = cell_line[0]\n",
        "        \n",
        "        # Construct cell-line specific pileup directory\n",
        "        pileup_dir = base_pileup_dir / cell_line_name / \"pileup_mod\"\n",
        "        \n",
        "        if not pileup_dir.exists():\n",
        "            print(f\"Warning: Pileup directory does not exist: {pileup_dir}\")\n",
        "            # Fill with zeros for this cell line\n",
        "            for row in group_df.iter_rows(named=True):\n",
        "                atac_pileup_arrays[row['idx']] = np.zeros(4096)\n",
        "            continue\n",
        "        \n",
        "        print(f\"Processing {len(group_df)} regions for cell line: {cell_line_name}\")\n",
        "        \n",
        "        # Process all regions for this cell line at once\n",
        "        atac_arrays_dict = process_pileups_batch(pileup_dir, group_df)\n",
        "        \n",
        "        # Assign to the correct positions in the final array\n",
        "        for idx, atac_array in atac_arrays_dict.items():\n",
        "            atac_pileup_arrays[idx] = atac_array\n",
        "    \n",
        "    print(\"Converting to final numpy arrays...\")\n",
        "    # Convert to numpy array\n",
        "    atac_pileup_list = np.array(atac_pileup_arrays)\n",
        "    \n",
        "    print(\"Processing complete!\")\n",
        "    return attrs_list, atac_attribution_list, atac_pileup_list\n",
        "\n",
        "attrs_list, atac_attribution_list, atac_pileup_list = process_region_data_fast(df_positive_correct)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Import additional required libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "seaborn.set_style('whitegrid')\n",
        "from tangermeme.plot import plot_logo\n",
        "from tangermeme.seqlet import recursive_seqlets, tfmodisco_seqlets\n",
        "from matplotlib.colors import TwoSlopeNorm\n",
        "\n",
        "\n",
        "\n",
        "def get_seqlets(attrs_list, use_absolute_values=False, method='recursive', **kwargs):\n",
        "    \"\"\"\n",
        "    Extract seqlets from attribution data using one of two methods.\n",
        "\n",
        "    Args:\n",
        "        attrs_list (list): List of attribution arrays for each sample.\n",
        "        use_absolute_values (bool): Whether to use absolute attribution values for peak finding.\n",
        "        method (str): The seqlet calling method to use. Either 'tfmodisco' (default)\n",
        "                      or 'recursive'.\n",
        "        **kwargs: Method-specific arguments.\n",
        "            For 'tfmodisco':\n",
        "                - See tangermeme.seqlet.tfmodisco_seqlets documentation. Common\n",
        "                  parameters include `window_size` and `flank`.\n",
        "            For 'recursive':\n",
        "                - threshold (float): p-value threshold for a span to be considered\n",
        "                                     a seqlet. Default: 0.01.\n",
        "                - min_seqlet_len (int): Minimum length of a seqlet. Default: 4.\n",
        "                - max_seqlet_len (int): Maximum length of a seqlet. Default: 25.\n",
        "                - additional_flanks (int): Number of base pairs to add to each side\n",
        "                                           of a discovered seqlet. Default: 0.\n",
        "    \"\"\"\n",
        "    attrs_array = np.stack(attrs_list, axis=0)\n",
        "\n",
        "    # Sum attributions across one-hot encoded dimension to get a per-position score\n",
        "    summed_attrs = attrs_array.sum(axis=1)\n",
        "\n",
        "    # Optionally use absolute values\n",
        "    if use_absolute_values:\n",
        "        summed_attrs = np.abs(summed_attrs)\n",
        "\n",
        "    if method == 'tfmodisco':\n",
        "        seqlets = tfmodisco_seqlets(summed_attrs, **kwargs)\n",
        "    elif method == 'recursive':\n",
        "        # recursive_seqlets uses a p-value based threshold.\n",
        "        # We set some reasonable defaults based on its documentation.\n",
        "        r_kwargs = {\n",
        "            'threshold': 0.01,\n",
        "            'min_seqlet_len': 4,\n",
        "            'max_seqlet_len': 25,\n",
        "            'additional_flanks': 0\n",
        "        }\n",
        "        r_kwargs.update(kwargs)\n",
        "        seqlets = recursive_seqlets(summed_attrs, **r_kwargs)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown seqlet calling method: '{method}'. Choose 'tfmodisco' or 'recursive'.\")\n",
        "\n",
        "\n",
        "    nt_idx = {0: 'A', 1: 'C', 2: 'G', 3: 'T'}\n",
        "\n",
        "    # Add sequences to seqlets df\n",
        "    sequences = []\n",
        "    for i in range(len(seqlets)):\n",
        "        sample = seqlets.iloc[i]\n",
        "        start = int(sample['start'])\n",
        "        end = int(sample['end'])\n",
        "        sample_idx = int(sample['example_idx'])\n",
        "\n",
        "        sample_attrs = attrs_array[sample_idx, :, start:end].T.squeeze()\n",
        "        hits = np.argmax(sample_attrs, axis=1)\n",
        "        seq = ''.join([nt_idx[i] for i in hits])\n",
        "        sequences.append(seq)\n",
        "    \n",
        "    seqlets['sequence'] = sequences\n",
        "    return seqlets\n",
        "def plot_seqlet_with_atac(seqlets, attrs_list, atac_attribution_list, atac_pileup_list, \n",
        "                         sample_rank=0, context_size=20, colormap='RdBu_r', equal_color_scale=False):\n",
        "    \"\"\"\n",
        "    Create a two-panel plot with a NON-SYMMETRIC color-normalized heatmap.\n",
        "    - Top: DNA base attributions (logo plot)  \n",
        "    - Bottom: ATAC pileup with attribution heatmap background (0 is always white)\n",
        "    \n",
        "    The color scale for the heatmap now stretches to the true min and max of the data in the window.\n",
        "    \"\"\"\n",
        "    # --- This part of the function is unchanged ---\n",
        "    sample = seqlets.iloc[[sample_rank]]\n",
        "    slice_idx = int(sample['example_idx'].tolist()[0])\n",
        "    sequence = sample['sequence'].tolist()[0]\n",
        "    start = int(sample['start'].tolist()[0])\n",
        "    end = int(sample['end'].tolist()[0])\n",
        "    p_value = sample['p-value'].tolist()[0]\n",
        "\n",
        "    seqlet_center = (start + end) // 2\n",
        "    seqlet_length = end - start\n",
        "    total_window_size = seqlet_length + (2 * context_size)\n",
        "    window_start = seqlet_center - (total_window_size // 2)\n",
        "    window_end = seqlet_center + (total_window_size // 2)\n",
        "    window_start = max(0, window_start)\n",
        "    window_end = min(4096, window_end)\n",
        "    if window_end - window_start < total_window_size:\n",
        "        if window_start == 0:\n",
        "            window_end = min(4096, window_start + total_window_size)\n",
        "        elif window_end == 4096:\n",
        "            window_start = max(0, window_end - total_window_size)\n",
        "    \n",
        "    print(f\"Seqlet: {start}-{end} (center: {seqlet_center})\")\n",
        "    print(f\"Window: {window_start}-{window_end} (size: {window_end - window_start})\")\n",
        "    print(f\"P-Value: {p_value}\")\n",
        "    \n",
        "    plot_coords = np.arange(window_start, window_end)\n",
        "    X_attr = attrs_list[slice_idx].astype(np.float64)\n",
        "    atac_attr = atac_attribution_list[slice_idx].astype(np.float64)\n",
        "    atac_pileup = atac_pileup_list[slice_idx].astype(np.float64)\n",
        "    X_attr_windowed = X_attr[:, window_start:window_end]\n",
        "    atac_attr_windowed = atac_attr[window_start:window_end]\n",
        "    atac_pileup_windowed = atac_pileup[window_start:window_end]\n",
        "    \n",
        "    print(f\"Windowed shapes: DNA={X_attr_windowed.shape}, ATAC_attr={atac_attr_windowed.shape}, ATAC_pileup={atac_pileup_windowed.shape}\")\n",
        "\n",
        "    fig = plt.figure(figsize=(18, 10), dpi=300)\n",
        "    gs = fig.add_gridspec(2, 2, width_ratios=[20, 1], height_ratios=[1, 1], hspace=0.3, wspace=0.02)\n",
        "    ax1 = fig.add_subplot(gs[0, 0])\n",
        "    ax2 = fig.add_subplot(gs[1, 0])\n",
        "    cax = fig.add_subplot(gs[1, 1])\n",
        "\n",
        "    # Top panel logic remains the same...\n",
        "    plot_logo(X_attr_windowed, ax=ax1)\n",
        "    n_ticks = 8\n",
        "    tick_positions = np.linspace(0, len(plot_coords)-1, n_ticks)\n",
        "    tick_labels = np.linspace(plot_coords[0], plot_coords[-1], n_ticks).astype(int)\n",
        "    ax1.set_xticks(tick_positions)\n",
        "    ax1.set_xticklabels(tick_labels)\n",
        "    ax1.set_xlabel(\"Genomic Coordinate\")\n",
        "    ax1.set_ylabel(\"DNA Attributions\")\n",
        "    ax1.set_title(f\"DNA Base Attributions | Sample: {slice_idx} | {sequence}\")\n",
        "\n",
        "    # --- This part of the function is also unchanged ---\n",
        "    heatmap_height = 25\n",
        "    attr_heatmap = np.tile(atac_attr_windowed, (heatmap_height, 1))\n",
        "    max_pileup = np.max(atac_pileup_windowed) if len(atac_pileup_windowed) > 0 else 1\n",
        "    y_max = max_pileup * 1.1\n",
        "\n",
        "    # <<< MODIFIED SECTION >>>\n",
        "    # CREATE THE ASYMMETRIC NORMALIZER CENTERED AT 0\n",
        "    if atac_attr_windowed.size > 0:\n",
        "        # Get the true min and max of the data in the window\n",
        "        vmin_val = np.min(atac_attr_windowed)\n",
        "        vmax_val = np.max(atac_attr_windowed)\n",
        "    else:\n",
        "        # Handle empty window case\n",
        "        vmin_val, vmax_val = -1, 1\n",
        "\n",
        "    if equal_color_scale:\n",
        "        # Handle empty window case for np.abs\n",
        "        if atac_attr_windowed.size > 0:\n",
        "            vabs_max = np.max(np.abs(atac_attr_windowed))\n",
        "        else:\n",
        "            vabs_max = 1\n",
        "        vmin_val = -vabs_max\n",
        "        vmax_val = vabs_max \n",
        "        \n",
        "    # Create the normalizer with the actual data bounds, keeping 0 as the center\n",
        "    norm = TwoSlopeNorm(vcenter=0, vmin=vmin_val, vmax=vmax_val)\n",
        "    # <<< END OF MODIFIED SECTION >>>\n",
        "\n",
        "    # Create the heatmap background using the SAME coordinate system and the NEW norm\n",
        "    im = ax2.imshow(attr_heatmap, \n",
        "                    cmap=colormap,\n",
        "                    aspect='auto',\n",
        "                    extent=[plot_coords[0], plot_coords[-1], 0, y_max],\n",
        "                    alpha=0.7,\n",
        "                    interpolation='bilinear',\n",
        "                    norm=norm) # Apply the new asymmetric normalizer\n",
        "    \n",
        "    # --- The rest of the function is unchanged ---\n",
        "    ax2.plot(plot_coords, atac_pileup_windowed, color='black', linewidth=2.5, \n",
        "             label='ATAC-seq Pileup', alpha=0.9)\n",
        "    ax2.set_xlim(plot_coords[0], plot_coords[-1])\n",
        "    \n",
        "    cbar = plt.colorbar(im, cax=cax)\n",
        "    cbar.set_label('ATAC Attribution', rotation=270, labelpad=15, fontsize=11)\n",
        "    \n",
        "    ax2.set_xlabel(\"Genomic Coordinate\")\n",
        "    ax2.set_ylabel(\"ATAC-seq Signal\")\n",
        "    ax2.set_title(f\"ATAC Pileup with Attribution Heatmap | Sample: {slice_idx}\")\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "seqlets = get_seqlets(attrs_list, method='tfmodisco')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "plot_seqlet_with_atac(seqlets, attrs_list,atac_attribution_list=atac_attribution_list, atac_pileup_list=atac_pileup_list, sample_rank=4, context_size=2000)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming your normalization functions are defined as before:\n",
        "# normalize_rows_minmax, normalize_rows_by_peak, normalize_rows_by_central_peak\n",
        "\n",
        "def normalize_rows_minmax(arr: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Normalize each row to range [0, 1].\"\"\"\n",
        "    min_vals = arr.min(axis=1, keepdims=True)\n",
        "    max_vals = arr.max(axis=1, keepdims=True)\n",
        "    denom = np.clip(max_vals - min_vals, a_min=1e-6, a_max=None)\n",
        "    return (arr - min_vals) / denom\n",
        "\n",
        "def normalize_rows_by_peak(arr: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Normalize each row by its maximum value.\"\"\"\n",
        "    max_vals = arr.max(axis=1, keepdims=True)\n",
        "    denom = np.clip(max_vals, a_min=1e-6, a_max=None)\n",
        "    return arr / denom\n",
        "\n",
        "def normalize_rows_by_central_peak(arr: np.ndarray, window_size: int = 100) -> np.ndarray:\n",
        "    \"\"\"Normalize each row by the maximum value in its central region.\"\"\"\n",
        "    center = arr.shape[1] // 2\n",
        "    half_window = window_size // 2\n",
        "    # Ensure central_region slicing is robust\n",
        "    start_slice = max(0, center - half_window)\n",
        "    end_slice = min(arr.shape[1], center + half_window + (window_size % 2)) # ensure full window size\n",
        "    central_region = arr[:, start_slice:end_slice]\n",
        "    \n",
        "    if central_region.shape[1] == 0: # Handle case where central window is empty (e.g. arr is too small)\n",
        "        peak_vals = np.ones((arr.shape[0], 1)) * 1e-6 # Avoid division by zero, effectively no scaling\n",
        "    else:\n",
        "        peak_vals = central_region.max(axis=1, keepdims=True)\n",
        "        \n",
        "    denom = np.clip(peak_vals, a_min=1e-6, a_max=None)\n",
        "    return arr / denom\n",
        "\n",
        "\n",
        "def plot_avg_atac_and_attribution(atac_pileup_list: np.ndarray,\n",
        "                                  atac_attribution_list: np.ndarray,\n",
        "                                  normalize_pileup_method: str = \"minmax\",\n",
        "                                  normalize_attribution_method: str = \"peak\",\n",
        "                                  context_size: int = None, # New parameter for zooming\n",
        "                                  central_peak_norm_window_size: int = 100 # Pass through for central peak norm\n",
        "                                  ):\n",
        "    \"\"\"\n",
        "    Plot average ATAC pileup and attribution across all samples.\n",
        "    Normalization methods can be specified.\n",
        "    Allows zooming to a central context window.\n",
        "    \"\"\"\n",
        "    processed_pileup = atac_pileup_list.copy()\n",
        "    pileup_norm_label = \" (Raw)\"\n",
        "    if normalize_pileup_method == \"minmax\":\n",
        "        processed_pileup = normalize_rows_minmax(processed_pileup)\n",
        "        pileup_norm_label = \" (Min-Max Normalized by Sample)\"\n",
        "    elif normalize_pileup_method == \"peak\":\n",
        "        processed_pileup = normalize_rows_by_peak(processed_pileup)\n",
        "        pileup_norm_label = \" (Peak Normalized by Sample)\"\n",
        "    elif normalize_pileup_method == \"central_peak\":\n",
        "        processed_pileup = normalize_rows_by_central_peak(processed_pileup, window_size=central_peak_norm_window_size)\n",
        "        pileup_norm_label = \" (Central Peak Normalized by Sample)\"\n",
        "    elif normalize_pileup_method != \"none\":\n",
        "        raise ValueError(f\"Unknown normalize_pileup_method: {normalize_pileup_method}\")\n",
        "\n",
        "    processed_attribution = atac_attribution_list.copy()\n",
        "    attr_norm_label = \" (Raw)\"\n",
        "    if normalize_attribution_method == \"minmax\":\n",
        "        processed_attribution = normalize_rows_minmax(processed_attribution)\n",
        "        attr_norm_label = \" (Min-Max Normalized by Sample)\"\n",
        "    elif normalize_attribution_method == \"peak\":\n",
        "        processed_attribution = normalize_rows_by_peak(processed_attribution)\n",
        "        attr_norm_label = \" (Peak Normalized by Sample)\"\n",
        "    elif normalize_attribution_method == \"central_peak\":\n",
        "        processed_attribution = normalize_rows_by_central_peak(processed_attribution, window_size=central_peak_norm_window_size)\n",
        "        attr_norm_label = f\" (Central Peak[{central_peak_norm_window_size}bp] Normalized by Sample)\"\n",
        "    elif normalize_attribution_method != \"none\":\n",
        "        raise ValueError(f\"Unknown normalize_attribution_method: {normalize_attribution_method}\")\n",
        "\n",
        "    mean_pileup = processed_pileup.mean(axis=0)\n",
        "    mean_attr = processed_attribution.mean(axis=0)\n",
        "    \n",
        "    full_length = len(mean_pileup)\n",
        "    x_coords = np.arange(full_length)\n",
        "\n",
        "    # Determine window for plotting\n",
        "    if context_size is not None and 0 < context_size < full_length:\n",
        "        center_idx = full_length // 2\n",
        "        half_cs = context_size // 2\n",
        "        \n",
        "        win_start = max(0, center_idx - half_cs)\n",
        "        win_end = min(full_length, win_start + context_size)\n",
        "        \n",
        "        # Adjust start if win_end hit full_length, to try to maintain context_size\n",
        "        if win_end == full_length:\n",
        "            win_start = max(0, full_length - context_size)\n",
        "\n",
        "        mean_pileup_to_plot = mean_pileup[win_start:win_end]\n",
        "        mean_attr_to_plot = mean_attr[win_start:win_end]\n",
        "        x_to_plot = x_coords[win_start:win_end]\n",
        "        plot_title_suffix = f\" (Region: {win_start} - {win_end-1})\"\n",
        "    else:\n",
        "        mean_pileup_to_plot = mean_pileup\n",
        "        mean_attr_to_plot = mean_attr\n",
        "        x_to_plot = x_coords\n",
        "        plot_title_suffix = \" (Full View)\"\n",
        "\n",
        "    if len(x_to_plot) == 0:\n",
        "        print(\"Warning: Calculated plot window is empty. Plotting full range instead.\")\n",
        "        mean_pileup_to_plot = mean_pileup\n",
        "        mean_attr_to_plot = mean_attr\n",
        "        x_to_plot = x_coords\n",
        "        plot_title_suffix = \" (Full View - Empty Zoom Attempt)\"\n",
        "\n",
        "\n",
        "    fig, ax1 = plt.subplots(figsize=(18, 5), dpi=150)\n",
        "\n",
        "    ax1.plot(x_to_plot, mean_pileup_to_plot, color='black', label=\"Avg ATAC Pileup\")\n",
        "    ax1.set_ylabel(f\"Pileup{pileup_norm_label}\", color='black')\n",
        "    ax1.tick_params(axis='y', labelcolor='black')\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(x_to_plot, mean_attr_to_plot, color='red', alpha=0.6, label=\"Avg ATAC Attribution\")\n",
        "    ax2.set_ylabel(f\"Attribution{attr_norm_label}\", color='red')\n",
        "    ax2.tick_params(axis='y', labelcolor='red')\n",
        "\n",
        "    ax1.set_title(\"Average ATAC Pileup and Attribution\" + plot_title_suffix)\n",
        "    if len(x_to_plot) > 0:\n",
        "        ax1.set_xlabel(f\"Position ({x_to_plot[0]}\u2013{x_to_plot[-1]})\")\n",
        "    else:\n",
        "        ax1.set_xlabel(\"Position (Empty Range)\")\n",
        "        \n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    lines, labels = ax1.get_legend_handles_labels()\n",
        "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "    ax2.legend(lines + lines2, labels + labels2, loc=\"upper right\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_avg_atac_and_attribution(\n",
        "    atac_pileup_list, # Make sure this is defined from your data\n",
        "    atac_attribution_list, # Make sure this is defined from your data\n",
        "    normalize_pileup_method=\"none\",\n",
        "    normalize_attribution_method=\"none\",\n",
        "    central_peak_norm_window_size=100,\n",
        "    context_size=4000\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def plot_average_half_profiles(attribution_data: np.ndarray, data_label: str = \"ATAC Track Attribution\"):\n",
        "    num_samples, L = attribution_data.shape\n",
        "    mid_idx = L // 2\n",
        "\n",
        "    left_half_data = attribution_data[:, :mid_idx]\n",
        "    right_half_data = attribution_data[:, mid_idx:]\n",
        "\n",
        "    avg_left_profile = np.mean(left_half_data, axis=0)\n",
        "    # Flip the right half for comparison: last position of right half becomes first, etc.\n",
        "    avg_right_profile_flipped = np.mean(right_half_data[:, ::-1], axis=0) \n",
        "    \n",
        "    x_axis_half = np.arange(mid_idx)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(x_axis_half, avg_left_profile, label='Average Left Half Profile', color='blue', alpha=0.8)\n",
        "    plt.plot(x_axis_half, avg_right_profile_flipped, label='Average Right Half Profile (Flipped)', color='red', linestyle='--', alpha=0.8)\n",
        "    \n",
        "    # Difference plot\n",
        "    # plt.plot(x_axis_half, avg_left_profile - avg_right_profile_flipped, label='Difference (Left - Flipped Right)', color='green', alpha=0.5)\n",
        "\n",
        "    plt.xlabel(f\"Position from Center (0 to {mid_idx-1})\")\n",
        "    plt.ylabel(\"Average Attribution Score\")\n",
        "    plt.title(f\"Comparison of Average Left vs. Flipped Right {data_label} Profiles\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.axhline(0, color='black', linewidth=0.5)\n",
        "    plt.show()\n",
        "\n",
        "# --- Example Usage ---\n",
        "plot_average_half_profiles(atac_attribution_list, \n",
        "                           data_label=\"ATAC Track Attribution (Positive Correct Sites)\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "# Assume 'atac_attribution_list' is your data (e.g., from df_positive_correct or df_balanced)\n",
        "# It should have shape (number_of_samples, 4096)\n",
        "\n",
        "def analyze_attribution_asymmetry(attribution_data: np.ndarray, \n",
        "                                  data_label: str = \"ATAC Track Attribution\",\n",
        "                                  metric: str = 'sum_raw'):\n",
        "    \"\"\"\n",
        "    Analyzes the asymmetry of attribution scores between the left and right halves of sequences.\n",
        "\n",
        "    Args:\n",
        "        attribution_data: Numpy array of shape (num_samples, sequence_length).\n",
        "        data_label: String label for the data being analyzed (for plot titles).\n",
        "        metric: The metric to use for quantifying attribution:\n",
        "                'sum_raw': Sum of raw attribution scores.\n",
        "                'sum_positive': Sum of positive attribution scores.\n",
        "                'sum_absolute': Sum of absolute attribution scores.\n",
        "    \"\"\"\n",
        "    num_samples, L = attribution_data.shape\n",
        "\n",
        "    if L % 2 != 0:\n",
        "        print(f\"Warning: Sequence length {L} is odd. The exact center split might be slightly imbalanced.\")\n",
        "    \n",
        "    # Define split point\n",
        "    # For L=4096, mid_idx = 2048. Left: 0 to 2047. Right: 2048 to 4095.\n",
        "    mid_idx = L // 2\n",
        "\n",
        "    left_half_data = attribution_data[:, :mid_idx]\n",
        "    right_half_data = attribution_data[:, mid_idx:]\n",
        "\n",
        "    if metric == 'sum_raw':\n",
        "        left_values = np.sum(left_half_data, axis=1)\n",
        "        right_values = np.sum(right_half_data, axis=1)\n",
        "        metric_label = \"Sum of Raw Attributions\"\n",
        "    elif metric == 'sum_positive':\n",
        "        left_values = np.sum(np.maximum(0, left_half_data), axis=1)\n",
        "        right_values = np.sum(np.maximum(0, right_half_data), axis=1)\n",
        "        metric_label = \"Sum of Positive Attributions\"\n",
        "    elif metric == 'sum_absolute':\n",
        "        left_values = np.sum(np.abs(left_half_data), axis=1)\n",
        "        right_values = np.sum(np.abs(right_half_data), axis=1)\n",
        "        metric_label = \"Sum of Absolute Attributions\"\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown metric: {metric}. Choose from 'sum_raw', 'sum_positive', 'sum_absolute'.\")\n",
        "\n",
        "    asymmetry_scores = left_values - right_values # Positive means left > right\n",
        "\n",
        "    # --- Statistical Analysis ---\n",
        "    mean_asymmetry = np.mean(asymmetry_scores)\n",
        "    median_asymmetry = np.median(asymmetry_scores)\n",
        "    # Paired t-test (to see if the mean difference is significantly different from 0)\n",
        "    # Or Wilcoxon signed-rank test if normality is a concern (often more robust for scores)\n",
        "    # t_stat, p_value = stats.ttest_rel(left_values, right_values)\n",
        "    wilcoxon_stat, p_value = stats.wilcoxon(left_values, right_values, alternative='two-sided' if mean_asymmetry !=0 else 'greater') # H1: left != right\n",
        "    \n",
        "    # --- Plotting Histogram ---\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(asymmetry_scores, bins=50, edgecolor='k', alpha=0.7)\n",
        "    plt.axvline(mean_asymmetry, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean_asymmetry:.2f}')\n",
        "    plt.axvline(median_asymmetry, color='orange', linestyle='dashed', linewidth=2, label=f'Median: {median_asymmetry:.2f}')\n",
        "    plt.axvline(0, color='black', linestyle='solid', linewidth=1)\n",
        "    plt.xlabel(f\"{metric_label} (Left Half - Right Half)\")\n",
        "    plt.ylabel(\"Number of Samples\")\n",
        "    plt.title(f\"Distribution of {data_label} Asymmetry ({metric_label})\\nWilcoxon P-value (Left vs Right): {p_value:.2e}\")\n",
        "    plt.legend()\n",
        "    plt.grid(axis='y', alpha=0.5)\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"--- Asymmetry Analysis for {data_label} using {metric_label} ---\")\n",
        "    print(f\"Number of samples: {num_samples}\")\n",
        "    print(f\"Mean Asymmetry (Left - Right): {mean_asymmetry:.4f}\")\n",
        "    print(f\"Median Asymmetry (Left - Right): {median_asymmetry:.4f}\")\n",
        "    print(f\"Standard Deviation of Asymmetry Scores: {np.std(asymmetry_scores):.4f}\")\n",
        "    print(f\"Wilcoxon signed-rank test statistic: {wilcoxon_stat:.4f}, P-value: {p_value:.4g}\")\n",
        "\n",
        "    if p_value < 0.05:\n",
        "        if mean_asymmetry > 0:\n",
        "            print(\"Result: Statistically significant evidence that the Left side has larger attribution.\")\n",
        "        elif mean_asymmetry < 0:\n",
        "            print(\"Result: Statistically significant evidence that the Right side has larger attribution.\")\n",
        "        else:\n",
        "            print(\"Result: Statistically significant, but mean difference is zero (might indicate symmetric deviations). Check median.\")\n",
        "    else:\n",
        "        print(\"Result: No statistically significant difference found between left and right side attributions based on this metric.\")\n",
        "    print(\"--------------------------------------------------\\n\")\n",
        "    return asymmetry_scores, p_value\n",
        "\n",
        "# --- Example Usage ---\n",
        "# Make sure 'atac_attribution_list' is loaded and available\n",
        "# For example, if you processed 'df_positive_correct':\n",
        "# _, _, atac_attribution_list_positive = process_region_data_fast(df_positive_correct) # Assuming this returns it\n",
        "\n",
        "# If atac_attribution_list is already the numpy array from your previous code:\n",
        "analyze_attribution_asymmetry(atac_attribution_list, \n",
        "                              data_label=\"ATAC Track Attribution (Positive Correct Sites)\", \n",
        "                              metric='sum_raw')\n",
        "\n",
        "# analyze_attribution_asymmetry(atac_attribution_list, \n",
        "#                               data_label=\"ATAC Track Attribution (Positive Correct Sites)\", \n",
        "#                               metric='sum_positive')\n",
        "\n",
        "# analyze_attribution_asymmetry(atac_attribution_list, \n",
        "#                               data_label=\"ATAC Track Attribution (Positive Correct Sites)\", \n",
        "#                               metric='sum_absolute')\n",
        "\n",
        "# You can also apply this to your DNA base attributions (attrs_list)\n",
        "# Assuming attrs_list has shape (num_samples, 4, 4096)\n",
        "# To analyze DNA base attributions, you might want to sum across the A,C,G,T dimension first\n",
        "# or analyze each base channel separately if that's meaningful.\n",
        "# For a general DNA importance, you could sum absolute values across bases, then sum across length:\n",
        "# dna_importance_per_position = np.sum(np.abs(attrs_list), axis=1) # Shape: (num_samples, 4096)\n",
        "# analyze_attribution_asymmetry(dna_importance_per_position, \n",
        "#                               data_label=\"Summed Absolute DNA Base Attribution (Positive Correct Sites)\", \n",
        "#                               metric='sum_raw') # 'sum_raw' here means sum of summed_abs_dna_attr\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats # Make sure scipy is imported for stats.wilcoxon\n",
        "\n",
        "# Make sure your 'analyze_attribution_asymmetry' and 'plot_average_half_profiles'\n",
        "# functions from the previous response are defined in your environment.\n",
        "# (I'm re-pasting them here for completeness in this code block,\n",
        "#  but you likely already have them)\n",
        "\n",
        "def analyze_attribution_asymmetry(attribution_data: np.ndarray,\n",
        "                                  data_label: str = \"ATAC Track Attribution\",\n",
        "                                  metric: str = 'sum_raw'):\n",
        "    \"\"\"\n",
        "    Analyzes the asymmetry of attribution scores between the left and right halves of sequences.\n",
        "    (Same function as provided before)\n",
        "    \"\"\"\n",
        "    num_samples, L = attribution_data.shape\n",
        "    if L % 2 != 0:\n",
        "        print(f\"Warning: Sequence length {L} is odd. The exact center split might be slightly imbalanced.\")\n",
        "    mid_idx = L // 2\n",
        "    left_half_data = attribution_data[:, :mid_idx]\n",
        "    right_half_data = attribution_data[:, mid_idx:]\n",
        "\n",
        "    if metric == 'sum_raw':\n",
        "        left_values = np.sum(left_half_data, axis=1)\n",
        "        right_values = np.sum(right_half_data, axis=1)\n",
        "        metric_label = \"Sum of Raw Attributions\"\n",
        "    elif metric == 'sum_positive':\n",
        "        left_values = np.sum(np.maximum(0, left_half_data), axis=1)\n",
        "        right_values = np.sum(np.maximum(0, right_half_data), axis=1)\n",
        "        metric_label = \"Sum of Positive Attributions\"\n",
        "    elif metric == 'sum_absolute':\n",
        "        left_values = np.sum(np.abs(left_half_data), axis=1)\n",
        "        right_values = np.sum(np.abs(right_half_data), axis=1)\n",
        "        metric_label = \"Sum of Absolute Attributions\"\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown metric: {metric}. Choose from 'sum_raw', 'sum_positive', 'sum_absolute'.\")\n",
        "\n",
        "    asymmetry_scores = left_values - right_values\n",
        "    mean_asymmetry = np.mean(asymmetry_scores)\n",
        "    median_asymmetry = np.median(asymmetry_scores)\n",
        "    # Use alternative='two-sided' for a general test of difference,\n",
        "    # or specify 'greater' or 'less' if you have a directional hypothesis beforehand.\n",
        "    # Given your previous finding, you might expect left > right, so alternative='greater' for left_values > right_values\n",
        "    # (which means asymmetry_scores > 0).\n",
        "    # For wilcoxon(x, y, alternative='greater'), it tests if median of x-y is greater than 0.\n",
        "    # So, wilcoxon(asymmetry_scores, alternative='greater') if testing if median asymmetry > 0\n",
        "    # or wilcoxon(left_values, right_values, alternative='greater')\n",
        "    \n",
        "    # Test if median of (left_values - right_values) is different from 0\n",
        "    # If testing if left is specifically larger, H1 is median(left-right) > 0\n",
        "    alt_hypothesis = 'two-sided'\n",
        "    if np.abs(mean_asymmetry) > 1e-9 : # If there's a clear direction in the mean\n",
        "        alt_hypothesis = 'greater' if mean_asymmetry > 0 else 'less'\n",
        "\n",
        "    # For a paired test where we look at the differences:\n",
        "    # We test if the median of these differences is non-zero.\n",
        "    # If asymmetry_scores = left - right, we want to test if median(asymmetry_scores) is > 0 if we expect left > right\n",
        "    if len(asymmetry_scores) > 0 and not np.all(asymmetry_scores == 0): # Wilcoxon needs non-identical samples or non-zero differences\n",
        "        try:\n",
        "            # We are testing the 'asymmetry_scores' directly. If we expect left > right, then asymmetry_scores > 0.\n",
        "            # So, alternative='greater' tests if the median of asymmetry_scores is greater than 0.\n",
        "            wilcoxon_stat, p_value = stats.wilcoxon(asymmetry_scores, alternative='greater' if mean_asymmetry > 0 else ('less' if mean_asymmetry < 0 else 'two-sided'))\n",
        "\n",
        "        except ValueError as e: # Can happen if all differences are zero\n",
        "            print(f\"Wilcoxon test could not be performed: {e}\")\n",
        "            wilcoxon_stat, p_value = np.nan, np.nan\n",
        "    else:\n",
        "        wilcoxon_stat, p_value = np.nan, np.nan\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(asymmetry_scores, bins=50, edgecolor='k', alpha=0.7)\n",
        "    plt.axvline(mean_asymmetry, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean_asymmetry:.2f}')\n",
        "    plt.axvline(median_asymmetry, color='orange', linestyle='dashed', linewidth=2, label=f'Median: {median_asymmetry:.2f}')\n",
        "    plt.axvline(0, color='black', linestyle='solid', linewidth=1)\n",
        "    plt.xlabel(f\"{metric_label} (Left Half - Right Half)\")\n",
        "    plt.ylabel(\"Number of Samples\")\n",
        "    plt.title(f\"Distribution of {data_label} Asymmetry ({metric_label})\\nWilcoxon P-value (Median Diff > 0 or < 0): {p_value:.2e}\")\n",
        "    plt.legend()\n",
        "    plt.grid(axis='y', alpha=0.5)\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"--- Asymmetry Analysis for {data_label} using {metric_label} ---\")\n",
        "    print(f\"Number of samples: {num_samples}\")\n",
        "    print(f\"Mean Asymmetry (Left - Right): {mean_asymmetry:.4f}\")\n",
        "    print(f\"Median Asymmetry (Left - Right): {median_asymmetry:.4f}\")\n",
        "    print(f\"Standard Deviation of Asymmetry Scores: {np.std(asymmetry_scores):.4f}\")\n",
        "    print(f\"Wilcoxon signed-rank test statistic: {wilcoxon_stat:.4f}, P-value: {p_value:.4g}\")\n",
        "\n",
        "    if not np.isnan(p_value) and p_value < 0.05:\n",
        "        if mean_asymmetry > 0: # And alternative was 'greater'\n",
        "            print(\"Result: Statistically significant evidence that the Left side has larger attribution.\")\n",
        "        elif mean_asymmetry < 0: # And alternative was 'less'\n",
        "             print(\"Result: Statistically significant evidence that the Right side has larger attribution.\")\n",
        "        else: # This case might occur if alternative was 'two-sided' and p < 0.05 but mean is near 0\n",
        "             print(\"Result: Statistically significant difference detected, but mean is close to zero. Inspect median and distribution.\")\n",
        "    else:\n",
        "        print(\"Result: No statistically significant difference found (or test not performed) between left and right side attributions based on this metric.\")\n",
        "    print(\"--------------------------------------------------\\n\")\n",
        "    return asymmetry_scores, p_value\n",
        "\n",
        "\n",
        "def plot_average_half_profiles(attribution_data: np.ndarray, data_label: str = \"Generic Attribution\"):\n",
        "    \"\"\"\n",
        "    Plots the average profile of the left half vs. the average of the flipped right half.\n",
        "    (Same function as provided before)\n",
        "    \"\"\"\n",
        "    num_samples, L = attribution_data.shape\n",
        "    mid_idx = L // 2\n",
        "    left_half_data = attribution_data[:, :mid_idx]\n",
        "    right_half_data = attribution_data[:, mid_idx:]\n",
        "    avg_left_profile = np.mean(left_half_data, axis=0)\n",
        "    avg_right_profile_flipped = np.mean(right_half_data[:, ::-1], axis=0)\n",
        "    x_axis_half = np.arange(mid_idx)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(x_axis_half, avg_left_profile, label='Average Left Half Profile', color='blue', alpha=0.8)\n",
        "    plt.plot(x_axis_half, avg_right_profile_flipped, label='Average Right Half Profile (Flipped)', color='red', linestyle='--', alpha=0.8)\n",
        "    plt.xlabel(f\"Position from Center (0 to {mid_idx-1})\")\n",
        "    plt.ylabel(\"Average Attribution Score\")\n",
        "    plt.title(f\"Comparison of Average Left vs. Flipped Right {data_label} Profiles\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.axhline(0, color='black', linewidth=0.5)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# --- Applying to DNA Base Attributions ---\n",
        "\n",
        "# Assume 'attrs_list' is your DNA base attribution data, loaded as a NumPy array\n",
        "# with shape (number_of_samples, 4, 4096).\n",
        "# For example, this might come from your 'process_region_data_fast' function\n",
        "# or directly from where you load your data.\n",
        "\n",
        "# Example: if attrs_list is loaded:\n",
        "# attrs_list, _, _ = process_region_data_fast(df_positive_correct) # Make sure this is correctly populated\n",
        "\n",
        "if 'attrs_list' in locals() and isinstance(attrs_list, np.ndarray) and attrs_list.ndim == 3 and attrs_list.shape[1] == 4:\n",
        "    print(\"Processing DNA base attributions (attrs_list)...\")\n",
        "    \n",
        "    # 1. Preprocess attrs_list to get a per-position DNA importance score.\n",
        "    # We sum the absolute values of attributions across the 4 bases (A,C,G,T) for each position.\n",
        "    # This gives a single score per position representing total DNA nucleotide importance.\n",
        "    # The resulting array will have non-negative values.\n",
        "    dna_importance_scores_per_position = np.sum(np.abs(attrs_list), axis=1)\n",
        "    # This array should have shape (number_of_samples, 4096)\n",
        "\n",
        "    # 2. Analyze asymmetry for these DNA importance scores.\n",
        "    # Since dna_importance_scores_per_position contains only non-negative values (it's a sum of absolute values),\n",
        "    # using metric='sum_raw', 'sum_positive', or 'sum_absolute' on *these already processed scores*\n",
        "    # will yield the same result for 'left_values' and 'right_values'.\n",
        "    # 'sum_raw' is clear and sufficient here.\n",
        "    print(\"\\nAnalyzing asymmetry for Summed Absolute DNA Base Attributions:\")\n",
        "    dna_asymmetry_scores, dna_p_value = analyze_attribution_asymmetry(\n",
        "        dna_importance_scores_per_position,\n",
        "        data_label=\"Summed Absolute DNA Base Attribution\",\n",
        "        metric='sum_raw' \n",
        "    )\n",
        "\n",
        "    # 3. Plot average half profiles for DNA importance\n",
        "    plot_average_half_profiles(\n",
        "        dna_importance_scores_per_position,\n",
        "        data_label=\"Summed Absolute DNA Base Attribution\"\n",
        "    )\n",
        "\n",
        "else:\n",
        "    print(\"Warning: 'attrs_list' not found or not in the expected format (num_samples, 4, 4096). Skipping DNA base attribution asymmetry analysis.\")\n",
        "\n",
        "# For reference, how you might have called it for ATAC track attributions:\n",
        "    print(\"\\nAnalyzing asymmetry for ATAC Track Attributions (Sum of Raw):\")\n",
        "    analyze_attribution_asymmetry(\n",
        "        atac_attribution_list,\n",
        "        data_label=\"ATAC Track Attribution\",\n",
        "        metric='sum_raw'\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def plot_seqlet_with_atac(seqlets, attrs_list, atac_attribution_list, atac_pileup_list, \n",
        "                         sample_rank=0, context_size=20, colormap='RdBu_r', \n",
        "                         equal_color_scale=False, num_bins=None):\n",
        "    \"\"\"\n",
        "    Create a two-panel plot with a NON-SYMMETRIC color-normalized heatmap.\n",
        "    - Top: DNA base attributions (logo plot)  \n",
        "    - Bottom: ATAC pileup with attribution heatmap background (0 is always white)\n",
        "    \n",
        "    The color scale for the heatmap now stretches to the true min and max of the data in the window.\n",
        "    \n",
        "    Args:\n",
        "        ... (previous arguments) ...\n",
        "        num_bins (int, optional): If specified, draws vertical dashed lines \n",
        "                                  to divide the plot into this many bins. \n",
        "                                  Defaults to None.\n",
        "    \"\"\"\n",
        "    # --- This part of the function is unchanged ---\n",
        "    sample = seqlets.iloc[[sample_rank]]\n",
        "    slice_idx = int(sample['example_idx'].tolist()[0])\n",
        "    sequence = sample['sequence'].tolist()[0]\n",
        "    start = int(sample['start'].tolist()[0])\n",
        "    end = int(sample['end'].tolist()[0])\n",
        "    p_value = sample['p-value'].tolist()[0]\n",
        "\n",
        "    seqlet_center = (start + end) // 2\n",
        "    seqlet_length = end - start\n",
        "    total_window_size = seqlet_length + (2 * context_size)\n",
        "    window_start = seqlet_center - (total_window_size // 2)\n",
        "    window_end = seqlet_center + (total_window_size // 2)\n",
        "    window_start = max(0, window_start)\n",
        "    window_end = min(4096, window_end)\n",
        "    if window_end - window_start < total_window_size:\n",
        "        if window_start == 0:\n",
        "            window_end = min(4096, window_start + total_window_size)\n",
        "        elif window_end == 4096:\n",
        "            window_start = max(0, window_end - total_window_size)\n",
        "    \n",
        "    print(f\"Seqlet: {start}-{end} (center: {seqlet_center})\")\n",
        "    print(f\"Window: {window_start}-{window_end} (size: {window_end - window_start})\")\n",
        "    print(f\"P-Value: {p_value}\")\n",
        "    \n",
        "    plot_coords = np.arange(window_start, window_end)\n",
        "    X_attr = attrs_list[slice_idx].astype(np.float64)\n",
        "    atac_attr = atac_attribution_list[slice_idx].astype(np.float64)\n",
        "    atac_pileup = atac_pileup_list[slice_idx].astype(np.float64)\n",
        "    X_attr_windowed = X_attr[:, window_start:window_end]\n",
        "    atac_attr_windowed = atac_attr[window_start:window_end]\n",
        "    atac_pileup_windowed = atac_pileup[window_start:window_end]\n",
        "    \n",
        "    print(f\"Windowed shapes: DNA={X_attr_windowed.shape}, ATAC_attr={atac_attr_windowed.shape}, ATAC_pileup={atac_pileup_windowed.shape}\")\n",
        "\n",
        "    fig = plt.figure(figsize=(18, 10), dpi=300)\n",
        "    gs = fig.add_gridspec(2, 2, width_ratios=[20, 1], height_ratios=[1, 1], hspace=0.3, wspace=0.02)\n",
        "    ax1 = fig.add_subplot(gs[0, 0])\n",
        "    ax2 = fig.add_subplot(gs[1, 0])\n",
        "    cax = fig.add_subplot(gs[1, 1])\n",
        "\n",
        "    # --- Top panel and heatmap logic remains the same ---\n",
        "    plot_logo(X_attr_windowed, ax=ax1)\n",
        "    n_ticks = 8\n",
        "    tick_positions = np.linspace(0, len(plot_coords)-1, n_ticks)\n",
        "    tick_labels = np.linspace(plot_coords[0], plot_coords[-1], n_ticks).astype(int)\n",
        "    ax1.set_xticks(tick_positions)\n",
        "    ax1.set_xticklabels(tick_labels)\n",
        "    ax1.set_xlabel(\"Genomic Coordinate\")\n",
        "    ax1.set_ylabel(\"DNA Attributions\")\n",
        "    ax1.set_title(f\"DNA Base Attributions | Sample: {slice_idx} | {sequence}\")\n",
        "\n",
        "    heatmap_height = 25\n",
        "    attr_heatmap = np.tile(atac_attr_windowed, (heatmap_height, 1))\n",
        "    max_pileup = np.max(atac_pileup_windowed) if len(atac_pileup_windowed) > 0 else 1\n",
        "    y_max = max_pileup * 1.1\n",
        "\n",
        "    if atac_attr_windowed.size > 0:\n",
        "        vmin_val = np.min(atac_attr_windowed)\n",
        "        vmax_val = np.max(atac_attr_windowed)\n",
        "    else:\n",
        "        vmin_val, vmax_val = -1, 1\n",
        "\n",
        "    if equal_color_scale:\n",
        "        if atac_attr_windowed.size > 0:\n",
        "            vabs_max = np.max(np.abs(atac_attr_windowed))\n",
        "        else:\n",
        "            vabs_max = 1\n",
        "        vmin_val = -vabs_max\n",
        "        vmax_val = vabs_max \n",
        "        \n",
        "    norm = TwoSlopeNorm(vcenter=0, vmin=vmin_val, vmax=vmax_val)\n",
        "\n",
        "    im = ax2.imshow(attr_heatmap, \n",
        "                    cmap=colormap,\n",
        "                    aspect='auto',\n",
        "                    extent=[plot_coords[0], plot_coords[-1], 0, y_max],\n",
        "                    alpha=0.7,\n",
        "                    interpolation='bilinear',\n",
        "                    norm=norm)\n",
        "    \n",
        "    # --- The rest of the plotting logic is also unchanged ---\n",
        "    ax2.plot(plot_coords, atac_pileup_windowed, color='black', linewidth=2.5, \n",
        "             label='ATAC-seq Pileup', alpha=0.9)\n",
        "    ax2.set_xlim(plot_coords[0], plot_coords[-1])\n",
        "    \n",
        "    cbar = plt.colorbar(im, cax=cax)\n",
        "    cbar.set_label('ATAC Attribution', rotation=270, labelpad=15, fontsize=11)\n",
        "    \n",
        "    ax2.set_xlabel(\"Genomic Coordinate\")\n",
        "    ax2.set_ylabel(\"ATAC-seq Signal\")\n",
        "    ax2.set_title(f\"ATAC Pileup with Attribution Heatmap | Sample: {slice_idx}\")\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    # <<< MODIFIED SECTION >>>\n",
        "    # IF num_bins IS SPECIFIED, DRAW VERTICAL DASHED LINES\n",
        "    if num_bins is not None and num_bins > 1:\n",
        "        # Calculate the genomic coordinates for the bin dividers\n",
        "        bin_edges = np.linspace(window_start, window_end, num_bins + 1)\n",
        "        \n",
        "        # Draw a line for each internal bin edge on both plots\n",
        "        for edge in bin_edges[1:-1]:\n",
        "            ax1.axvline(x=edge, color='grey', linestyle='--', linewidth=1.2, alpha=0.7)\n",
        "            ax2.axvline(x=edge, color='grey', linestyle='--', linewidth=1.2, alpha=0.7)\n",
        "    # <<< END OF MODIFIED SECTION >>>\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === PWM-based scoring of top seqlets =====================================\n",
        "# Author: automated addition\n",
        "\n",
        "from typing import List, Tuple, Dict\n",
        "import random\n",
        "\n",
        "\n",
        "def load_jaspar_pwm(jaspar_path: str, pseudocount: float = 1e-2) -> np.ndarray:\n",
        "    \"\"\"Load a JASPAR motif and return a (4, L) probability matrix in A,C,G,T order.\"\"\"\n",
        "    base_order = [\"A\", \"C\", \"G\", \"T\"]\n",
        "    rows: Dict[str, List[float]] = {b: [] for b in base_order}\n",
        "    with open(jaspar_path) as f:\n",
        "        for line in f:\n",
        "            if line.startswith(\">\") or not line.strip():\n",
        "                # skip header / empty lines\n",
        "                continue\n",
        "            base, rest = line.split(\"[\", 1)\n",
        "            counts = [float(x) for x in rest.strip(\"[] \\n\").split()]\n",
        "            base_key = base.strip()\n",
        "            if base_key in rows:\n",
        "                rows[base_key].extend(counts)\n",
        "    counts_arr = np.array([rows[b] for b in base_order], dtype=float) + pseudocount\n",
        "    pwm = counts_arr / counts_arr.sum(axis=0, keepdims=True)  # column-wise normalisation\n",
        "    return pwm\n",
        "\n",
        "\n",
        "_BASE2IDX = {b: i for i, b in enumerate(\"ACGT\")}\n",
        "_COMP = str.maketrans(\"ACGT\", \"TGCA\")\n",
        "\n",
        "\n",
        "def _seq_logprob(seq: str, pwm: np.ndarray, offset: int) -> float:\n",
        "    \"\"\"Correctly calculate log-probability for a sequence at a given PWM offset.\"\"\"\n",
        "    idx = np.fromiter((_BASE2IDX.get(b, 0) for b in seq), dtype=int)\n",
        "    # The columns in the PWM to select for each base in the sequence\n",
        "    cols = np.arange(offset, offset + len(seq))\n",
        "    # Select the probability of each base at its corresponding position and sum the logs.\n",
        "    # The previous version incorrectly indexed a sub-matrix, this now correctly\n",
        "    # selects the diagonal elements representing the actual match.\n",
        "    return np.log(pwm[idx, cols] + 1e-9).sum()\n",
        "\n",
        "\n",
        "def pwm_best_score(seq: str, pwm: np.ndarray) -> float:\n",
        "    \"\"\"Return best log-probability of *seq* (both strands) sliding along *pwm*.\"\"\"\n",
        "    L_pwm = pwm.shape[1]\n",
        "    L_seq = len(seq)\n",
        "    if L_seq > L_pwm:\n",
        "        # If seqlet longer than PWM, truncate center to fit.\n",
        "        start = (L_seq - L_pwm) // 2\n",
        "        seq = seq[start : start + L_pwm]\n",
        "        L_seq = len(seq)\n",
        "    best = -np.inf\n",
        "    # Forward strand\n",
        "    for off in range(L_pwm - L_seq + 1):\n",
        "        best = max(best, _seq_logprob(seq, pwm, off))\n",
        "    # Reverse complement\n",
        "    seq_rc = seq.translate(_COMP)[::-1]\n",
        "    for off in range(L_pwm - L_seq + 1):\n",
        "        best = max(best, _seq_logprob(seq_rc, pwm, off))\n",
        "    return best\n",
        "\n",
        "\n",
        "def score_and_display_seqlets(\n",
        "    winning_seqlets,\n",
        "    jaspar_path: str,\n",
        "    motif_name: str,\n",
        "    num_bins: int,\n",
        "    score_top_n: int = None,\n",
        "    display_top_n: int = 20,\n",
        "    sort_by: str = \"log-prob\",\n",
        "    num_permutations: int = 0,\n",
        "    null_method: str = 'permute',\n",
        "):\n",
        "    \"\"\"\n",
        "    Loads a PWM, scores seqlets, and prints top results. Can also generate null\n",
        "    distribution scores using one of two methods.\n",
        "\n",
        "    Args:\n",
        "        winning_seqlets: DataFrame containing seqlets and their 'bin_index'.\n",
        "        jaspar_path: Path to the JASPAR motif file.\n",
        "        motif_name: Name of the motif for labeling the output (e.g., \"AR\").\n",
        "        num_bins: The total number of bins seqlets were sorted into.\n",
        "        score_top_n (int, optional): The number of top frequent seqlets to score.\n",
        "                                     If None, all unique seqlets are scored. Defaults to None.\n",
        "        display_top_n (int): The number of top-scored seqlets to print for each bin.\n",
        "                             Defaults to 20.\n",
        "        sort_by (str): How to rank the final displayed list: 'log-prob' or 'frequency'.\n",
        "        num_permutations (int): Number of random sequences to generate and score\n",
        "                                for each occurrence of a seqlet. Defaults to 0.\n",
        "        null_method (str): Method for generating the null distribution.\n",
        "                             'permute': Shuffle the original seqlet (preserves\n",
        "                             base composition).\n",
        "                             'random': Generate a new random sequence of the same\n",
        "                             length. Defaults to 'permute'.\n",
        "    \n",
        "    Returns:\n",
        "        A tuple containing two lists:\n",
        "        - Real scores: log-probs for actual seqlets, weighted by frequency.\n",
        "        - Null scores: log-probs for the generated null sequences.\n",
        "    \"\"\"\n",
        "    if winning_seqlets.empty:\n",
        "        print(f\"Skipping scoring for {motif_name}: `winning_seqlets` is empty.\")\n",
        "        return [], []\n",
        "\n",
        "    score_label = f\"top {score_top_n}\" if score_top_n is not None else \"all\"\n",
        "    print(f\"\\nScoring {score_label} most frequent seqlets per bin against {motif_name} PWM (Null method: '{null_method}')... \ud83d\udd0d\")\n",
        "    pwm = load_jaspar_pwm(jaspar_path)\n",
        "\n",
        "    scores_to_return = []\n",
        "    null_scores_to_return = []\n",
        "    for b in range(num_bins):\n",
        "        seqs_in_bin = winning_seqlets[winning_seqlets[\"bin_index\"] == b][\"sequence\"]\n",
        "        if seqs_in_bin.empty:\n",
        "            continue\n",
        "        \n",
        "        # Get counts for all unique sequences in the bin\n",
        "        seq_counts = seqs_in_bin.value_counts()\n",
        "        \n",
        "        # Decide which sequences to score based on score_top_n\n",
        "        if score_top_n is not None:\n",
        "            seqs_to_score = seq_counts.head(score_top_n)\n",
        "        else:\n",
        "            seqs_to_score = seq_counts\n",
        "        \n",
        "        scored: List[Tuple[str, int, float]] = []\n",
        "        for seq, count in seqs_to_score.items():\n",
        "            score = pwm_best_score(seq, pwm)\n",
        "            scored.append((seq, count, score))\n",
        "            # Append score `count` times for an accurate distribution plot\n",
        "            scores_to_return.extend([score] * count)\n",
        "\n",
        "            # Generate and score null distribution\n",
        "            if num_permutations > 0:\n",
        "                for _ in range(num_permutations):\n",
        "                    # For each time the original seqlet appeared, generate one null version\n",
        "                    for _ in range(count):\n",
        "                        if null_method == 'permute':\n",
        "                            null_seq_list = random.sample(seq, len(seq))\n",
        "                            null_seq = \"\".join(null_seq_list)\n",
        "                        elif null_method == 'random':\n",
        "                            null_seq = \"\".join(random.choices(\"ACGT\", k=len(seq)))\n",
        "                        else:\n",
        "                            raise ValueError(f\"Unknown null_method: '{null_method}'. Choose 'permute' or 'random'.\")\n",
        "                        \n",
        "                        null_score = pwm_best_score(null_seq, pwm)\n",
        "                        null_scores_to_return.append(null_score)\n",
        "\n",
        "        # --- Sorting Logic for Display ---\n",
        "        if sort_by == \"log-prob\":\n",
        "            # Sort by score (log-prob), descending\n",
        "            scored.sort(key=lambda x: x[2], reverse=True)\n",
        "            sort_label = \"best-matching first\"\n",
        "        elif sort_by == \"frequency\":\n",
        "            # The list is already sorted by frequency from value_counts()\n",
        "            sort_label = \"most frequent first\"\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid sort_by value: '{sort_by}'. Must be 'log-prob' or 'frequency'.\")\n",
        "\n",
        "        print(f\"\\nBin {b}: Scored {len(scored)} unique seqlets vs {motif_name} \u2192 displaying top {min(display_top_n, len(scored))} ({sort_label})\")\n",
        "        for rank, (seq, count, sc) in enumerate(scored[:display_top_n], 1):\n",
        "            print(f\"  {rank:2d}. {seq:>12s} (n={count:<2})   log-prob = {sc:6.2f}\")\n",
        "    \n",
        "    return scores_to_return, null_scores_to_return\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# --- Step 0: Generate all possible seqlets from the entire dataset ---\n",
        "print(\"Generating all seqlets from the dataset... \ud83e\uddec\")\n",
        "all_seqlets = get_seqlets(attrs_list, method='tfmodisco')\n",
        "print(f\"Found a total of {len(all_seqlets)} seqlets across all samples.\")\n",
        "print(\"-\" * 20)\n",
        "\n",
        "\n",
        "# --- Configuration ---\n",
        "# Define which method to use for filtering samples:\n",
        "# 'rank': Use the original method (bin must be in Top N).\n",
        "# 'absolute': Bin's max signal must exceed a fixed value.\n",
        "# 'relative': Bin's max signal must be >= X% of the sample's max signal.\n",
        "METHOD = 'rank' # OPTIONS: 'rank', 'absolute', 'relative'\n",
        "\n",
        "NUM_BINS = 5\n",
        "TARGET_BIN_INDEX = 2\n",
        "\n",
        "# --- Settings for 'rank' method ---\n",
        "TOP_N_RANKING_ATTRIBUTION = 1   # Set to an integer (e.g., 1 for Top 1) or None to disable\n",
        "TOP_N_RANKING_PILEUP = None\n",
        "TOP_N_RANKING_ATTRS = None\n",
        "\n",
        "# --- Settings for 'absolute' method ---\n",
        "# Use the distribution plots from the next cell to help choose these values.\n",
        "ABS_THRESHOLD_ATTRIBUTION = 0.5  # Example value; set to a number or None\n",
        "ABS_THRESHOLD_PILEUP = None\n",
        "ABS_THRESHOLD_ATTRS = None\n",
        "\n",
        "# --- Settings for 'relative' method ---\n",
        "# Values should be between 0.0 and 1.0 (e.g., 0.7 for 70%)\n",
        "REL_THRESHOLD_ATTRIBUTION = 0.7 # Set to a float or None\n",
        "REL_THRESHOLD_PILEUP = None\n",
        "REL_THRESHOLD_ATTRS = None\n",
        "\n",
        "\n",
        "# --- Step 1: Robustly bin the data ---\n",
        "original_length = atac_attribution_list.shape[1]\n",
        "trimmed_length = original_length - (original_length % NUM_BINS)\n",
        "bin_size = trimmed_length // NUM_BINS\n",
        "\n",
        "print(f\"Original sequence length: {original_length}\")\n",
        "print(f\"Number of bins: {NUM_BINS}\")\n",
        "print(f\"Trimming sequences to length {trimmed_length} to create {NUM_BINS} equal bins of size {bin_size}bp.\")\n",
        "print(\"-\" * 20)\n",
        "\n",
        "# Trim and reshape 2D data arrays\n",
        "trimmed_attributions = atac_attribution_list[:, :trimmed_length]\n",
        "binned_attributions = trimmed_attributions.reshape(-1, NUM_BINS, bin_size)\n",
        "\n",
        "trimmed_pileups = atac_pileup_list[:, :trimmed_length]\n",
        "binned_pileups = trimmed_pileups.reshape(-1, NUM_BINS, bin_size)\n",
        "\n",
        "# <<< FIX: Process 3D attrs_list >>>\n",
        "# First, convert 3D attrs_list to 2D by taking the max across the base channels (axis=1)\n",
        "attrs_list_2d = attrs_list.max(axis=1)\n",
        "\n",
        "# Now, trim and reshape the new 2D array\n",
        "trimmed_attrs = attrs_list_2d[:, :trimmed_length]\n",
        "binned_attrs = trimmed_attrs.reshape(-1, NUM_BINS, bin_size)\n",
        "\n",
        "# Calculate max values per bin\n",
        "max_attributions_per_bin = binned_attributions.max(axis=2)\n",
        "max_pileups_per_bin = binned_pileups.max(axis=2)\n",
        "max_attrs_per_bin = binned_attrs.max(axis=2)\n",
        "\n",
        "\n",
        "# --- Step 2 & 3: Find winning samples based on the selected METHOD ---\n",
        "print(f\"\\n--- Analyzing Bin {TARGET_BIN_INDEX} using '{METHOD}' method ---\")\n",
        "\n",
        "final_mask = np.ones(atac_attribution_list.shape[0], dtype=bool)\n",
        "active_filters = []\n",
        "\n",
        "if METHOD == 'rank':\n",
        "    # Determine the rank of each bin within each sample\n",
        "    attribution_ranks = np.argsort(np.argsort(-max_attributions_per_bin, axis=1), axis=1)\n",
        "    pileup_ranks = np.argsort(np.argsort(-max_pileups_per_bin, axis=1), axis=1)\n",
        "    attrs_ranks = np.argsort(np.argsort(-max_attrs_per_bin, axis=1), axis=1)\n",
        "\n",
        "    if TOP_N_RANKING_ATTRIBUTION is not None:\n",
        "        mask = attribution_ranks[:, TARGET_BIN_INDEX] < TOP_N_RANKING_ATTRIBUTION\n",
        "        final_mask &= mask\n",
        "        active_filters.append(f\"Attribution Rank < {TOP_N_RANKING_ATTRIBUTION}\")\n",
        "    if TOP_N_RANKING_PILEUP is not None:\n",
        "        mask = pileup_ranks[:, TARGET_BIN_INDEX] < TOP_N_RANKING_PILEUP\n",
        "        final_mask &= mask\n",
        "        active_filters.append(f\"Pileup Rank < {TOP_N_RANKING_PILEUP}\")\n",
        "    if TOP_N_RANKING_ATTRS is not None:\n",
        "        mask = attrs_ranks[:, TARGET_BIN_INDEX] < TOP_N_RANKING_ATTRS\n",
        "        final_mask &= mask\n",
        "        active_filters.append(f\"DNA Attrs Rank < {TOP_N_RANKING_ATTRS}\")\n",
        "\n",
        "elif METHOD == 'absolute':\n",
        "    if ABS_THRESHOLD_ATTRIBUTION is not None:\n",
        "        target_bin_vals = max_attributions_per_bin[:, TARGET_BIN_INDEX]\n",
        "        final_mask &= (target_bin_vals >= ABS_THRESHOLD_ATTRIBUTION)\n",
        "        active_filters.append(f\"Attribution > {ABS_THRESHOLD_ATTRIBUTION}\")\n",
        "    if ABS_THRESHOLD_PILEUP is not None:\n",
        "        target_bin_vals = max_pileups_per_bin[:, TARGET_BIN_INDEX]\n",
        "        final_mask &= (target_bin_vals >= ABS_THRESHOLD_PILEUP)\n",
        "        active_filters.append(f\"Pileup > {ABS_THRESHOLD_PILEUP}\")\n",
        "    if ABS_THRESHOLD_ATTRS is not None:\n",
        "        target_bin_vals = max_attrs_per_bin[:, TARGET_BIN_INDEX]\n",
        "        final_mask &= (target_bin_vals >= ABS_THRESHOLD_ATTRS)\n",
        "        active_filters.append(f\"DNA Attrs > {ABS_THRESHOLD_ATTRS}\")\n",
        "\n",
        "elif METHOD == 'relative':\n",
        "    if REL_THRESHOLD_ATTRIBUTION is not None:\n",
        "        max_per_sample = max_attributions_per_bin.max(axis=1)\n",
        "        thresholds = max_per_sample * REL_THRESHOLD_ATTRIBUTION\n",
        "        target_bin_vals = max_attributions_per_bin[:, TARGET_BIN_INDEX]\n",
        "        final_mask &= (target_bin_vals >= thresholds)\n",
        "        active_filters.append(f\"Attribution >= {REL_THRESHOLD_ATTRIBUTION*100}% of max\")\n",
        "    if REL_THRESHOLD_PILEUP is not None:\n",
        "        max_per_sample = max_pileups_per_bin.max(axis=1)\n",
        "        thresholds = max_per_sample * REL_THRESHOLD_PILEUP\n",
        "        target_bin_vals = max_pileups_per_bin[:, TARGET_BIN_INDEX]\n",
        "        final_mask &= (target_bin_vals >= thresholds)\n",
        "        active_filters.append(f\"Pileup >= {REL_THRESHOLD_PILEUP*100}% of max\")\n",
        "    if REL_THRESHOLD_ATTRS is not None:\n",
        "        max_per_sample = max_attrs_per_bin.max(axis=1)\n",
        "        thresholds = max_per_sample * REL_THRESHOLD_ATTRS\n",
        "        target_bin_vals = max_attrs_per_bin[:, TARGET_BIN_INDEX]\n",
        "        final_mask &= (target_bin_vals >= thresholds)\n",
        "        active_filters.append(f\"DNA Attrs >= {REL_THRESHOLD_ATTRS*100}% of max\")\n",
        "\n",
        "else:\n",
        "    raise ValueError(f\"Unknown METHOD: '{METHOD}'. Choose from 'rank', 'absolute', 'relative'.\")\n",
        "\n",
        "\n",
        "final_indices = np.where(final_mask)[0]\n",
        "\n",
        "report_message = \" AND \".join(active_filters) if active_filters else \"No filters applied\"\n",
        "\n",
        "print(f\"Found {len(final_indices)} samples where Bin {TARGET_BIN_INDEX} met the criteria for: {report_message}.\")\n",
        "print(\"These are the sample indices:\")\n",
        "print(final_indices)\n",
        "print(\"-\" * 20)\n",
        "\n",
        "\n",
        "# --- Step 4: Find the Top 20 most common seqlets in each bin for the winning samples ---\n",
        "# (This section remains unchanged as it correctly uses `final_indices`)\n",
        "print(\"\\n--- Finding Most Common Seqlets in Winning Samples --- \ud83c\udfc6\")\n",
        "\n",
        "# Filter the master seqlet list to include only those from our winning samples\n",
        "winning_seqlets = all_seqlets[all_seqlets['example_idx'].isin(final_indices)].copy()\n",
        "\n",
        "if winning_seqlets.empty:\n",
        "    print(\"No seqlets were found in any of the winning samples that met the criteria.\")\n",
        "else:\n",
        "    # Filter for seqlets >= 5bp long\n",
        "    original_count = len(winning_seqlets)\n",
        "    winning_seqlets = winning_seqlets[winning_seqlets['sequence'].str.len() >= 5]\n",
        "    print(f\"Filtered for seqlets >= 5bp long. Kept {len(winning_seqlets)} out of {original_count} winning seqlets.\")\n",
        "\n",
        "    # Determine which bin each seqlet belongs to based on its midpoint\n",
        "    seqlet_midpoints = (winning_seqlets['start'] + winning_seqlets['end']) // 2\n",
        "    winning_seqlets['bin_index'] = seqlet_midpoints // bin_size\n",
        "\n",
        "    # Find the most common seqlets in each bin\n",
        "    for i in range(NUM_BINS):\n",
        "        seqlets_in_bin = winning_seqlets[winning_seqlets['bin_index'] == i]\n",
        "\n",
        "        if seqlets_in_bin.empty:\n",
        "            print(f\"\\nBin {i}: No seqlets found.\")\n",
        "        else:\n",
        "            sequence_counts = seqlets_in_bin['sequence'].value_counts()\n",
        "            total_in_bin = len(seqlets_in_bin)\n",
        "            print(f\"\\nBin {i}: Top seqlets (out of {total_in_bin} total):\")\n",
        "            top_seqlets = sequence_counts.head(20)\n",
        "            for rank, (sequence, count) in enumerate(top_seqlets.items(), 1):\n",
        "                print(f\"  {rank:>2}. '{sequence}' (found {count} times)\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === Visualize Distributions for Thresholding ===============================\n",
        "# Author: automated addition\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_max_value_distributions(\n",
        "    max_attributions_per_bin,\n",
        "    max_pileups_per_bin,\n",
        "    max_attrs_per_bin,\n",
        "    target_bin_index,\n",
        "    num_bins\n",
        "):\n",
        "    \"\"\"\n",
        "    Plots the distributions of max values within bins to help choose thresholds.\n",
        "    It shows the distribution for the target bin vs. all other bins.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(20, 5), dpi=150)\n",
        "    \n",
        "    all_bins_label = f\"Other Bins (not Bin {target_bin_index})\"\n",
        "    target_bin_label = f\"Target Bin ({target_bin_index})\"\n",
        "\n",
        "    # --- Attribution Plot ---\n",
        "    target_bin_attr = max_attributions_per_bin[:, target_bin_index]\n",
        "    other_bins_attr = np.delete(max_attributions_per_bin, target_bin_index, axis=1).flatten()\n",
        "    \n",
        "    sns.kdeplot(other_bins_attr, ax=axes[0], label=all_bins_label, fill=True)\n",
        "    sns.kdeplot(target_bin_attr, ax=axes[0], label=target_bin_label, fill=True, alpha=0.7)\n",
        "    axes[0].set_title(\"Distribution of Max ATAC Attributions per Bin\")\n",
        "    axes[0].set_xlabel(\"Max ATAC Attribution Score in Bin\")\n",
        "    axes[0].legend()\n",
        "\n",
        "    # --- Pileup Plot ---\n",
        "    target_bin_pileup = max_pileups_per_bin[:, target_bin_index]\n",
        "    other_bins_pileup = np.delete(max_pileups_per_bin, target_bin_index, axis=1).flatten()\n",
        "\n",
        "    sns.kdeplot(other_bins_pileup, ax=axes[1], label=all_bins_label, fill=True)\n",
        "    sns.kdeplot(target_bin_pileup, ax=axes[1], label=target_bin_label, fill=True, alpha=0.7)\n",
        "    axes[1].set_title(\"Distribution of Max ATAC Pileups per Bin\")\n",
        "    axes[1].set_xlabel(\"Max ATAC Pileup in Bin\")\n",
        "    axes[1].legend()\n",
        "\n",
        "    # --- DNA Attrs Plot ---\n",
        "    target_bin_dna = max_attrs_per_bin[:, target_bin_index]\n",
        "    other_bins_dna = np.delete(max_attrs_per_bin, target_bin_index, axis=1).flatten()\n",
        "    \n",
        "    sns.kdeplot(other_bins_dna, ax=axes[2], label=all_bins_label, fill=True)\n",
        "    sns.kdeplot(target_bin_dna, ax=axes[2], label=target_bin_label, fill=True, alpha=0.7)\n",
        "    axes[2].set_title(\"Distribution of Max DNA Attributions per Bin\")\n",
        "    axes[2].set_xlabel(\"Max DNA Attribution Score in Bin\")\n",
        "    axes[2].legend()\n",
        "    \n",
        "    plt.suptitle(f\"Max Value Distributions: Comparing Target Bin {target_bin_index} to All Others\", fontsize=16, y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Call the function using the data from the previous cell\n",
        "if 'max_attributions_per_bin' in globals():\n",
        "    plot_max_value_distributions(\n",
        "        max_attributions_per_bin,\n",
        "        max_pileups_per_bin,\n",
        "        max_attrs_per_bin,\n",
        "        TARGET_BIN_INDEX,\n",
        "        NUM_BINS\n",
        "    )\n",
        "else:\n",
        "    print(\"Run the previous cell to generate binned data before plotting.\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === Main Analysis Function ===============================================\n",
        "# Author: refactored analysis\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "def analyze_motif_in_bin(\n",
        "    winning_seqlets,\n",
        "    motif_name: str,\n",
        "    jaspar_path: str,\n",
        "    target_bin_index: int,\n",
        "    num_null_samples_per_seqlet: int = 1,\n",
        "    null_method: str = 'random',\n",
        "    display_top_n: int = 20,\n",
        "):\n",
        "    \"\"\"\n",
        "    Analyzes the top N most frequent seqlets from a specific bin against a\n",
        "    given motif, performs a statistical test, and plots the resulting score\n",
        "    distributions.\n",
        "    \"\"\"\n",
        "    # 1. Filter for the target bin and find top N frequent seqlets\n",
        "    seqlets_in_bin = winning_seqlets[winning_seqlets['bin_index'] == target_bin_index]\n",
        "    \n",
        "    if seqlets_in_bin.empty:\n",
        "        print(f\"No winning seqlets found in Bin {target_bin_index}. Skipping analysis for {motif_name}.\")\n",
        "        return\n",
        "\n",
        "    sequence_counts = seqlets_in_bin['sequence'].value_counts()\n",
        "    top_n_for_dist = sequence_counts.head(display_top_n)\n",
        "\n",
        "    print(f\"\\n--- Analyzing Top {len(top_n_for_dist)} Frequent Seqlets for Motif '{motif_name}' in Bin {target_bin_index} ---\")\n",
        "    print(f\"Found {len(seqlets_in_bin)} total seqlet occurrences in this bin.\")\n",
        "\n",
        "    # 2. Score all unique seqlets once for reporting best matches later\n",
        "    pwm = load_jaspar_pwm(jaspar_path)\n",
        "    scored_unique_seqlets: List[Tuple[str, int, float]] = []\n",
        "    for seq, count in sequence_counts.items():\n",
        "        score = pwm_best_score(seq, pwm)\n",
        "        scored_unique_seqlets.append((seq, count, score))\n",
        "\n",
        "    # 3. Build distributions using ONLY the top N frequent seqlets\n",
        "    real_scores = []\n",
        "    null_scores = []\n",
        "    for seq, count in top_n_for_dist.items():\n",
        "        # Find the pre-computed score for the sequence\n",
        "        score = next((s for q, c, s in scored_unique_seqlets if q == seq), 0)\n",
        "        real_scores.extend([score] * count)\n",
        "        \n",
        "        # Generate corresponding null scores\n",
        "        for _ in range(num_null_samples_per_seqlet * count):\n",
        "            if null_method == 'random':\n",
        "                null_seq = \"\".join(random.choices(\"ACGT\", k=len(seq)))\n",
        "            elif null_method == 'permute':\n",
        "                null_seq_list = random.sample(seq, len(seq))\n",
        "                null_seq = \"\".join(null_seq_list)\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid null_method: '{null_method}'. Choose 'permute' or 'random'.\")\n",
        "            \n",
        "            null_scores.append(pwm_best_score(null_seq, pwm))\n",
        "\n",
        "    # 4. Statistical Test\n",
        "    u_stat, p_value = None, None\n",
        "    if len(real_scores) > 0 and len(null_scores) > 0:\n",
        "        # Mann-Whitney U test: are scores from 'real_scores' stochastically greater than 'null_scores'?\n",
        "        u_stat, p_value = stats.mannwhitneyu(real_scores, null_scores, alternative='greater')\n",
        "\n",
        "    # 5. Visualization\n",
        "    plt.figure(figsize=(12, 7))\n",
        "    sns.kdeplot(null_scores, label=f\"'{null_method.capitalize()}' Scores (Null)\", fill=True, color=\"grey\", alpha=0.5)\n",
        "    sns.kdeplot(real_scores, label=f\"Actual Scores for '{motif_name}'\", fill=True, color=\"darkorange\", alpha=0.6)\n",
        "    \n",
        "    mean_real = np.mean(real_scores)\n",
        "    mean_null = np.mean(null_scores)\n",
        "    \n",
        "    plt.axvline(mean_null, color='black', linestyle='--', linewidth=2, label=f'Mean Null: {mean_null:.2f}')\n",
        "    plt.axvline(mean_real, color='darkred', linestyle='--', linewidth=2, label=f'Mean Actual: {mean_real:.2f}')\n",
        "    \n",
        "    title = f\"Significance of '{motif_name}' in Top {len(top_n_for_dist)} Frequent Seqlets from Bin {target_bin_index}\\n\"\n",
        "    if p_value is not None:\n",
        "        title += f\"Mann-Whitney U p-value (Actual > Null): {p_value:.2e}\"\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Log-Probability Score\")\n",
        "    plt.ylabel(\"Density\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "    # 6. Report\n",
        "    # Top N by frequency (already sorted in sequence_counts)\n",
        "    top_by_frequency = sequence_counts.head(display_top_n)\n",
        "    print(f\"\\n--- Top {display_top_n} Most FREQUENT Seqlets in Bin {target_bin_index} ---\")\n",
        "    for rank, (seq, count) in enumerate(top_by_frequency.items(), 1):\n",
        "        print(f\"  {rank:2d}. '{seq}' (found {count} times)\")\n",
        "\n",
        "    # Top N by PWM score\n",
        "    scored_unique_seqlets.sort(key=lambda x: x[2], reverse=True)\n",
        "    top_by_score = scored_unique_seqlets[:display_top_n]\n",
        "    print(f\"\\n--- Top {display_top_n} Best-MATCHING Seqlets to '{motif_name}' in Bin {target_bin_index} ---\")\n",
        "    for rank, (seq, count, score) in enumerate(top_by_score, 1):\n",
        "        print(f\"  {rank:2d}. '{seq}' (n={count})   log-prob = {score:.2f}\")\n",
        "\n",
        "    print(f\"\\n--- Statistical Summary for {motif_name} in Bin {target_bin_index} ---\")\n",
        "    print(f\" - Mean score of actual seqlets: {mean_real:.2f}\")\n",
        "    print(f\" - Mean score of null sequences: {mean_null:.2f}\")\n",
        "    if p_value is not None:\n",
        "        print(f\" - Mann-Whitney U p-value: {p_value:.4f}\")\n",
        "        if p_value < 0.05:\n",
        "            print(\"   -> Result: The motif is SIGNIFICANTLY enriched in this bin.\")\n",
        "        else:\n",
        "            print(\"   -> Result: The motif is NOT significantly enriched in this bin.\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === Main Analysis: Test Motif Significance in a Specific Bin ==============\n",
        "# Author: refactored analysis\n",
        "\n",
        "# --- Configuration ---\n",
        "# 1. Define the motifs you want to be able to test.\n",
        "MOTIF_DATABASE = {\n",
        "    \"AR\": jaspar_file, # From the first cell in the notebook\n",
        "    \"FOXA1\": \"/data1/datasets_1/human_cistrome/chip-atlas/peak_calls/tfbinding_scripts/tf-binding/src/analysis/interpretability/motifs/FOXA1.jaspar\",\n",
        "    \"CTCF\": \"/data1/datasets_1/human_cistrome/chip-atlas/peak_calls/tfbinding_scripts/tf-binding/src/analysis/interpretability/motifs/CTCF.jaspar\",\n",
        "    \"ERG\": \"/data1/datasets_1/human_cistrome/chip-atlas/peak_calls/tfbinding_scripts/tf-binding/src/analysis/interpretability/motifs/ERG.jaspar\",\n",
        "    \"HOXB13\": \"/data1/datasets_1/human_cistrome/chip-atlas/peak_calls/tfbinding_scripts/tf-binding/src/analysis/interpretability/motifs/HOXB13.jaspar\",\n",
        "    \"GATA1\": \"/data1/datasets_1/human_cistrome/chip-atlas/peak_calls/tfbinding_scripts/tf-binding/src/analysis/interpretability/motifs/GATA1.jaspar\",\n",
        "    \"NEUROD1\": \"/data1/datasets_1/human_cistrome/chip-atlas/peak_calls/tfbinding_scripts/tf-binding/src/analysis/interpretability/motifs/NEUROD1.jaspar\",\n",
        "    \"NFKB1\": \"/data1/datasets_1/human_cistrome/chip-atlas/peak_calls/tfbinding_scripts/tf-binding/src/analysis/interpretability/motifs/NFKB1.jaspar\"\n",
        "}\n",
        "\n",
        "# 2. CHOOSE which motif and bin to analyze.\n",
        "MOTIF_TO_ANALYZE = \"FOXA1\"\n",
        "BIN_TO_ANALYZE = 0 # An integer from 0 to NUM_BINS-1\n",
        "\n",
        "# --- Execution ---\n",
        "if \"winning_seqlets\" in globals() and not winning_seqlets.empty:\n",
        "    if MOTIF_TO_ANALYZE in MOTIF_DATABASE:\n",
        "        analyze_motif_in_bin(\n",
        "        winning_seqlets=winning_seqlets,\n",
        "            motif_name=MOTIF_TO_ANALYZE,\n",
        "            jaspar_path=MOTIF_DATABASE[MOTIF_TO_ANALYZE],\n",
        "            target_bin_index=BIN_TO_ANALYZE,\n",
        "            null_method='permute',\n",
        "            display_top_n=20,\n",
        "        )\n",
        "    else:\n",
        "        print(f\"Error: Motif '{MOTIF_TO_ANALYZE}' not found in MOTIF_DATABASE.\")\n",
        "        print(f\"Available motifs are: {list(MOTIF_DATABASE.keys())}\")\n",
        "else:\n",
        "    print(\"Please run the preceding cells to generate the 'winning_seqlets' DataFrame first.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === Systematic Analysis: Spatial Significance Heatmap ======================\n",
        "# Author: automated addition\n",
        "\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from matplotlib.colors import ListedColormap\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "\n",
        "import random\n",
        "\n",
        "# Seed the random number generator\n",
        "random.seed(42)\n",
        "\n",
        "def _calculate_p_value_for_bin(\n",
        "    winning_seqlets,\n",
        "    jaspar_path: str,\n",
        "    target_bin_index: int,\n",
        "    num_bins: int,\n",
        "    top_n_for_testing: int,\n",
        "    null_method: str\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    A helper function that calculates the Mann-Whitney U p-value for a given\n",
        "    motif in a specific bin without generating plots or text reports.\n",
        "    Returns 1.0 if not significant or if no seqlets are found.\n",
        "    \"\"\"\n",
        "    seqlets_in_bin = winning_seqlets[winning_seqlets['bin_index'] == target_bin_index]\n",
        "    if seqlets_in_bin.empty:\n",
        "        return 1.0\n",
        "\n",
        "    sequence_counts = seqlets_in_bin['sequence'].value_counts()\n",
        "    top_n_to_test = sequence_counts.head(top_n_for_testing)\n",
        "    \n",
        "    if top_n_to_test.empty:\n",
        "        return 1.0\n",
        "\n",
        "    # Score the top N seqlets and their null counterparts\n",
        "    pwm = load_jaspar_pwm(jaspar_path)\n",
        "    real_scores = []\n",
        "    null_scores = []\n",
        "    \n",
        "    for seq, count in top_n_to_test.items():\n",
        "        score = pwm_best_score(seq, pwm)\n",
        "        real_scores.extend([score] * count)\n",
        "        \n",
        "        for _ in range(count): # Generate one null sequence per real one\n",
        "            if null_method == 'random':\n",
        "                null_seq = \"\".join(random.choices(\"ACGT\", k=len(seq)))\n",
        "            elif null_method == 'permute':\n",
        "                null_seq = \"\".join(random.sample(seq, len(seq)))\n",
        "            else:\n",
        "                raise ValueError(\"Invalid null method\")\n",
        "            null_scores.append(pwm_best_score(null_seq, pwm))\n",
        "\n",
        "    # Perform statistical test\n",
        "    if not real_scores or not null_scores:\n",
        "        return 1.0\n",
        "    \n",
        "    try:\n",
        "        _, p_value = stats.mannwhitneyu(real_scores, null_scores, alternative='greater')\n",
        "        return p_value\n",
        "    except ValueError:\n",
        "        # This can happen if all scores are identical\n",
        "        return 1.0\n",
        "\n",
        "\n",
        "def plot_spatial_significance_heatmap(\n",
        "    winning_seqlets,\n",
        "    motif_database,\n",
        "    num_bins,\n",
        "    top_n_for_testing=20,\n",
        "    null_method='permute'\n",
        "):\n",
        "    \"\"\"\n",
        "    Generates a heatmap showing the statistical significance of multiple motifs\n",
        "    across all spatial bins. Uses a binary color scheme and custom annotations\n",
        "    (stars for significance, p-values otherwise).\n",
        "    \"\"\"\n",
        "    print(f\"--- Generating Spatial Significance Heatmap ---\")\n",
        "    print(f\"Testing top {top_n_for_testing} seqlets per bin using '{null_method}' null method.\")\n",
        "\n",
        "    # Create a DataFrame to store p-values\n",
        "    p_value_results = pd.DataFrame(\n",
        "        index=motif_database.keys(),\n",
        "        columns=range(num_bins),\n",
        "        dtype=float\n",
        "    )\n",
        "\n",
        "    # Loop through each motif and bin to calculate significance\n",
        "    for motif_name, jaspar_path in motif_database.items():\n",
        "        print(f\"Analyzing: {motif_name}...\")\n",
        "        for bin_idx in range(num_bins):\n",
        "            p_val = _calculate_p_value_for_bin(\n",
        "                winning_seqlets=winning_seqlets,\n",
        "                jaspar_path=jaspar_path,\n",
        "                target_bin_index=bin_idx,\n",
        "                num_bins=num_bins,\n",
        "                top_n_for_testing=top_n_for_testing,\n",
        "                null_method=null_method\n",
        "            )\n",
        "            p_value_results.loc[motif_name, bin_idx] = p_val\n",
        "    \n",
        "    # --- Custom Visualization Logic ---\n",
        "\n",
        "    # 1. Create a boolean matrix for significance (True if p < 0.05)\n",
        "    significance_matrix = p_value_results < 0.05\n",
        "\n",
        "    # 2. Create a matrix of custom string annotations\n",
        "    def format_p_value_annotation(p):\n",
        "        if p < 0.001: return '***'\n",
        "        if p < 0.01: return '**'\n",
        "        if p < 0.05: return '*'\n",
        "        return f'{p:.2f}'\n",
        "    \n",
        "    annotation_matrix = p_value_results.applymap(format_p_value_annotation)\n",
        "\n",
        "    # 3. Create a binary colormap\n",
        "    # A simple light grey for non-significant, and a medium blue for significant\n",
        "    cmap = ListedColormap(['#EAEAF2', '#5699C6'])\n",
        "\n",
        "    # 4. Plot the heatmap\n",
        "    plt.figure(figsize=(10, len(motif_database) * 1.5))\n",
        "    ax = sns.heatmap(\n",
        "        significance_matrix,    # Color cells based on True/False for significance\n",
        "        annot=annotation_matrix,  # Use the custom strings for text\n",
        "        fmt='s',                  # Tell heatmap the annotations are strings\n",
        "        cmap=cmap,\n",
        "        linewidths=1.5,\n",
        "        linecolor='white',\n",
        "        cbar=False,               # The binary color is self-explanatory\n",
        "        annot_kws={\"size\": 12}    # Adjust font size for readability\n",
        "    )\n",
        "    \n",
        "    # Add a legend manually for clarity\n",
        "    not_sig_patch = mpatches.Patch(color='#EAEAF2', label='Not Significant (p \u2265 0.05)')\n",
        "    sig_patch = mpatches.Patch(color='#5699C6', label='Significant (p < 0.05)')\n",
        "    plt.legend(handles=[sig_patch, not_sig_patch], bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
        "\n",
        "    ax.set_title(\"Motif Significance Across Spatial Bins\", fontsize=16, pad=20)\n",
        "    ax.set_xlabel(\"Bin Index\", fontsize=12)\n",
        "    ax.set_ylabel(\"Motif\", fontsize=12)\n",
        "    plt.tight_layout(rect=[0, 0, 0.85, 1]) # Adjust layout to make space for legend\n",
        "    plt.show()\n",
        "\n",
        "# --- Execution ---\n",
        "if \"winning_seqlets\" in globals() and not winning_seqlets.empty:\n",
        "    plot_spatial_significance_heatmap(\n",
        "        winning_seqlets=winning_seqlets,\n",
        "        motif_database=MOTIF_DATABASE,\n",
        "        num_bins=NUM_BINS,\n",
        "        top_n_for_testing=20,\n",
        "        null_method='permute' # Using 'permute' is a stricter, more standard control here\n",
        "    )\n",
        "else:\n",
        "    print(\"Please run the preceding cells to generate the 'winning_seqlets' DataFrame first.\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}